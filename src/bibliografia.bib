@online{cornelio_historia_2021,
  title =        {História da tecnologia: da pré-história ao
                  {Metaverso} • {Usemobile}},
  shorttitle =   {História da tecnologia},
  url =          {https://usemobile.com.br/historia-da-tecnologia/},
  abstract =     {Confira a história da tecnologia, conhecendo desde
                  os primórdios da humanidade até os adventos
                  contemporâneos.},
  language =     {pt-BR},
  urldate =      {2025-11-20},
  journal =      {Usemobile},
  author =       {Cornélio, Angelina},
  month =        nov,
  year =         {2021},
}

@online{google_global_2025,
  title =        {Global {AI} {Optimism} {Increases} as {Usage}
                  {Grows}},
  url =
                  {https://publicpolicy.google/article/global-ai-optimism-increases-as-usage-grows/},
  abstract =     {Based on the second annual global survey from Ipsos
                  and Google surveying 21,000 citizens across 21
                  countries, attitudes towards AI are trending more
                  positive as its use becomes more widespread.},
  language =     {en},
  urldate =      {2025-11-20},
  journal =      {Google Public Policy},
  author =       {Marr, Bernard},
  year =         {2025},
}

@online{marrOs15Maiores2023,
  type =         {News},
  title =        {Os 15 maiores riscos da inteligência artificial},
  author =       {Marr, Bernard},
  date =         {2023-06-05T06:00:55-03:00},
  url =
                  {https://forbes.com.br/forbes-tech/2023/06/os-15-maiores-riscos-da-inteligencia-artificial/},
  urldate =      {2025-11-16},
  abstract =     {Today we’re announcing new funding—\$40B at a \$300B
                  post-money valuation, which enables us to push the
                  frontiers of AI research even further, scale our
                  compute infrastructure, and deliver increasingly
                  powerful tools for the 500 million people who use
                  ChatGPT every week.},
  langid =       {brazilian},
  organization = {Forbes Brasil},
  year =         {2023},
}

@inproceedings{leeImpactGenerativeAI2025,
  title =        {The {{Impact}} of {{Generative AI}} on {{Critical
                  Thinking}}: {{Self-Reported Reductions}} in
                  {{Cognitive Effort}} and {{Confidence Effects From}}
                  a {{Survey}} of {{Knowledge Workers}}},
  shorttitle =   {The {{Impact}} of {{Generative AI}} on {{Critical
                  Thinking}}},
  booktitle =    {Proceedings of the 2025 {{CHI Conference}} on
                  {{Human Factors}} in {{Computing Systems}}},
  author =       {Lee, Hao-Ping (Hank) and Sarkar, Advait and
                  Tankelevitch, Lev and Drosos, Ian and Rintel, Sean
                  and Banks, Richard and Wilson, Nicholas},
  date =         {2025-04-25},
  series =       {{{CHI}} '25},
  pages =        {1--22},
  publisher =    {Association for Computing Machinery},
  location =     {New York, NY, USA},
  doi =          {10.1145/3706598.3713778},
  url =          {https://dl.acm.org/doi/10.1145/3706598.3713778},
  urldate =      {2025-11-16},
  abstract =     {The rise of Generative AI (GenAI) in knowledge
                  workflows raises questions about its impact on
                  critical thinking skills and practices. We survey
                  319 knowledge workers to investigate 1) when and how
                  they perceive the enaction of critical thinking when
                  using GenAI, and 2) when and why GenAI affects their
                  effort to do so. Participants shared 936 first-hand
                  examples of using GenAI in work tasks.
                  Quantitatively, when considering both task- and
                  user-specific factors, a user’s task-specific
                  self-confidence and confidence in GenAI are
                  predictive of whether critical thinking is enacted
                  and the effort of doing so in GenAI-assisted tasks.
                  Specifically, higher confidence in GenAI is
                  associated with less critical thinking, while higher
                  self-confidence is associated with more critical
                  thinking. Qualitatively, GenAI shifts the nature of
                  critical thinking toward information verification,
                  response integration, and task stewardship. Our
                  insights reveal new design challenges and
                  opportunities for developing GenAI tools for
                  knowledge work.},
  isbn =         {979-8-4007-1394-1},
  year =         2025,
}

@online{kosmynaYourBrainChatGPT2025,
  title =        {Your {{Brain}} on {{ChatGPT}}: {{Accumulation}} of
                  {{Cognitive Debt}} When {{Using}} an {{AI
                  Assistant}} for {{Essay Writing Task}}},
  shorttitle =   {Your {{Brain}} on {{ChatGPT}}},
  author =       {Kosmyna, Nataliya and Hauptmann, Eugene and Yuan, Ye
                  Tong and Situ, Jessica and Liao, Xian-Hao and
                  Beresnitzky, Ashly Vivian and Braunstein, Iris and
                  Maes, Pattie},
  date =         {2025-06-10},
  eprint =       {2506.08872},
  eprinttype =   {arXiv},
  eprintclass =  {cs},
  doi =          {10.48550/arXiv.2506.08872},
  url =          {http://arxiv.org/abs/2506.08872},
  urldate =      {2025-11-16},
  abstract =     {This study explores the neural and behavioral
                  consequences of LLM-assisted essay writing.
                  Participants were divided into three groups: LLM,
                  Search Engine, and Brain-only (no tools). Each
                  completed three sessions under the same condition.
                  In a fourth session, LLM users were reassigned to
                  Brain-only group (LLM-to-Brain), and Brain-only
                  users were reassigned to LLM condition
                  (Brain-to-LLM). A total of 54 participants took part
                  in Sessions 1-3, with 18 completing session 4. We
                  used electroencephalography (EEG) to assess
                  cognitive load during essay writing, and analyzed
                  essays using NLP, as well as scoring essays with the
                  help from human teachers and an AI judge. Across
                  groups, NERs, n-gram patterns, and topic ontology
                  showed within-group homogeneity. EEG revealed
                  significant differences in brain connectivity:
                  Brain-only participants exhibited the strongest,
                  most distributed networks; Search Engine users
                  showed moderate engagement; and LLM users displayed
                  the weakest connectivity. Cognitive activity scaled
                  down in relation to external tool use. In session 4,
                  LLM-to-Brain participants showed reduced alpha and
                  beta connectivity, indicating under-engagement.
                  Brain-to-LLM users exhibited higher memory recall
                  and activation of occipito-parietal and prefrontal
                  areas, similar to Search Engine users. Self-reported
                  ownership of essays was the lowest in the LLM group
                  and the highest in the Brain-only group. LLM users
                  also struggled to accurately quote their own work.
                  While LLMs offer immediate convenience, our findings
                  highlight potential cognitive costs. Over four
                  months, LLM users consistently underperformed at
                  neural, linguistic, and behavioral levels. These
                  results raise concerns about the long-term
                  educational implications of LLM reliance and
                  underscore the need for deeper inquiry into AI's
                  role in learning.},
  pubstate =     {prepublished},
  keywords =     {Computer Science - Artificial Intelligence},
  year =         {2025},
}

@misc{delikoura2025superficialoutputssuperficiallearning,
  title =        {From Superficial Outputs to Superficial Learning:
                  Risks of Large Language Models in Education},
  author =       {Iris Delikoura and Yi. R Fung and Pan Hui},
  year =         2025,
  eprint =       {2509.21972},
  archivePrefix ={arXiv},
  primaryClass = {cs.CY},
  url =          {https://arxiv.org/abs/2509.21972},
}

@online{openai_funding_2025,
  title =        {New funding to build towards {AGI}},
  url =          {https://openai.com/index/march-funding-updates/},
  abstract =     {Today we’re announcing new funding—\$40B at a \$300B
                  post-money valuation, which enables us to push the
                  frontiers of AI research even further, scale our
                  compute infrastructure, and deliver increasingly
                  powerful tools for the 500 million people who use
                  ChatGPT every week.},
  author =       {OpenAI},
  language =     {en-US},
  urldate =      {2025-11-21},
  year =         {2025},
}

@INPROCEEDINGS{10748289,
  author =       {Jia, Yuelong},
  booktitle =    {2024 3rd International Conference on Artificial
                  Intelligence, Internet of Things and Cloud Computing
                  Technology (AIoTC)},
  title =        {Analysis of the Impact of Artificial Intelligence on
                  Electricity Consumption},
  year =         2024,
  pages =        {57-60},
  keywords =     {Data centers;Electricity;Computational
                  modeling;Energy conservation;Demand response;Power
                  markets;Energy efficiency;Artificial
                  intelligence;Carbon;Uninterruptible power
                  systems;artificial intelligence;electricity
                  demand;demand response;energy efficiency},
  doi =          {10.1109/AIoTC63215.2024.10748289},
}

@INPROCEEDINGS{10983758,
  author =       {Al Azri, Kawther Zahir and Tumati, Raja and Al
                  Tarshi, Shahd Saud},
  booktitle =    {2025 International Conference for Artificial
                  Intelligence, Applications, Innovation and Ethics
                  (AI2E)},
  title =        {Impact of Artificial Intelligence on Student
                  Learning in Oman},
  year =         2025,
  pages =        {1-5},
  keywords =     {Surveys;Technological
                  innovation;Ethics;Education;Learning (artificial
                  intelligence);Chatbots;Internet;Artificial
                  intelligence tools;student learning;AI benefits;AI
                  challenges;AI education},
  doi =          {10.1109/AI2E64943.2025.10983758},
}

@article{jensen_generative_2025,
  title =        {Generative {AI} and higher education: a review of
                  claims from the first months of {ChatGPT}},
  volume =       89,
  issn =         {1573-174X},
  shorttitle =   {Generative {AI} and higher education},
  url =          {https://doi.org/10.1007/s10734-024-01265-3},
  doi =          {10.1007/s10734-024-01265-3},
  abstract =     {The release of the Artificial Intelligence (AI)
                  chatbot ChatGPT renewed discussions about how AI
                  would upend higher education. This paper presents a
                  critical analysis of “grey literature” claims made
                  in the first months after ChatGPT was made public,
                  exploring what these discussions might mobilise in
                  practice. We identified articles for inclusion
                  through a systematic search of five prominent higher
                  education sector outlets. The included articles were
                  thematically coded for claims about generative AI
                  and higher education. We identified ten claims:
                  Three about the nature of ChatGPT, four about
                  changing practices of institutions and teachers, and
                  three about new independent practices of students.
                  Overall, the claims present a positive perspective
                  on AI in higher education. While being perceived as
                  a disruption of the status quo, the authors
                  generally frame AI as a catalyst for existing
                  agendas, e.g. assessment reform, personalisation, or
                  inclusion. This suggests a focus on embracing the
                  affordances offered by AI and primarily addressing
                  risks by including AI in curricula. Furthermore, the
                  claims mainly portray students as either plagiarists
                  or victims of a failing educational system. The
                  paper proposes that a more critical interrogation of
                  generative AI, and the involvement of students in
                  the conversation, may be beneficial.},
  language =     {en},
  number =       4,
  urldate =      {2025-11-21},
  journal =      {Higher Education},
  author =       {Jensen, Lasse X. and Buhl, Alexandra and Sharma,
                  Anjali and Bearman, Margaret},
  month =        apr,
  year =         2025,
  keywords =     {ChatGPT, Artificial Intelligence, Generative AI,
                  Higher education, Grey literature, Scoping review},
  pages =        {1145--1161},
}

@inproceedings{gan_large_2023,
  title =        {Large {Language} {Models} in {Education}: {Vision}
                  and {Opportunities}},
  shorttitle =   {Large {Language} {Models} in {Education}},
  url =
                  {https://ieeexplore.ieee.org/abstract/document/10386291},
  doi =          {10.1109/BigData59044.2023.10386291},
  abstract =     {With the rapid development of artificial
                  intelligence technology, large language models
                  (LLMs) have become a hot research topic. Education
                  plays an important role in human social development
                  and progress. Traditional education faces challenges
                  such as individual student differences, insufficient
                  allocation of teaching resources, and assessment of
                  teaching effectiveness. Therefore, the applications
                  of LLMs in the field of digital/smart education have
                  broad prospects. The research on educational large
                  models (EduLLMs) is constantly evolving, providing
                  new methods and approaches to achieve personalized
                  learning, intelligent tutoring, and educational
                  assessment goals, thereby improving the quality of
                  education and the learning experience. This article
                  aims to investigate and summarize the application of
                  LLMs in smart education. It first introduces the
                  research background and motivation of LLMs and
                  explains the essence of LLMs. It then discusses the
                  relationship between digital education and EduLLMs
                  and summarizes the current research status of
                  educational large models. The main contributions are
                  the systematic summary and vision of the research
                  background, motivation, and application of large
                  models for education (LLM4Edu). By reviewing
                  existing research, this article provides guidance
                  and insights for educators, researchers, and
                  policy-makers to gain a deep understanding of the
                  potential and challenges of LLM4Edu. It further
                  provides guidance for further advancing the
                  development and application of LLM4Edu, while still
                  facing technical, ethical, and practical challenges
                  requiring further research and exploration.},
  urldate =      {2025-11-21},
  booktitle =    {2023 {IEEE} {International} {Conference} on {Big}
                  {Data} ({BigData})},
  author =       {Gan, Wensheng and Qi, Zhenlian and Wu, Jiayang and
                  Lin, Jerry Chun-Wei},
  month =        dec,
  year =         2023,
  keywords =     {Ethics, Analytical models, Systematics, Machine
                  vision, Education, Educational technology, Big Data,
                  artificial intelligence, LLMs, smart education,
                  vision, opportunities},
  pages =        {4776--4785},
}

@book{russell_artificial_2021,
  title =        {Artificial Intelligence: A Modern Approach},
  edition =      {4th},
  publisher =    {Pearson},
  author =       {Russell, Stuart J. and Norvig, Peter},
  year =         2021,
  address =      {Hoboken},
}

@article{mccarthy_proposal_2006,
  title =        {A Proposal for the Dartmouth Summer Research Project
                  on Artificial Intelligence, August 31, 1955},
  volume =       27,
  number =       4,
  journal =      {AI Magazine},
  author =       {McCarthy, John and Minsky, Marvin and Rochester,
                  Nathaniel and Shannon, Claude},
  year =         2006,
  pages =        {12--14},
  note =         {Republicação do documento original de 1955},
}

@article{turing_computing_1950,
  title =        {Computing Machinery and Intelligence},
  volume =       59,
  number =       236,
  journal =      {Mind},
  author =       {Turing, A. M.},
  year =         1950,
  pages =        {433--460},
}

@book{mitchell_machine_1997,
  title =        {Machine Learning},
  publisher =    {McGraw-Hill},
  author =       {Mitchell, Tom M.},
  year =         1997,
  address =      {New York},
}

@online{unesco_guidance_2023,
  title =        {Guidance for generative AI in education and
                  research},
  url =          {https://unesdoc.unesco.org/ark:/48223/pf0000386693},
  author =       {{UNESCO}},
  year =         {2023},
  urldate =      {2025-11-21},
  organization = {United Nations Educational, Scientific and Cultural
                  Organization},
}

@book{goodfellow_deep_2016,
  title =        {Deep Learning},
  author =       {Goodfellow, Ian and Bengio, Yoshua and Courville,
                  Aaron},
  publisher =    {MIT Press},
  note =         {http://www.deeplearningbook.org},
  year =         2016,
  address =      {Cambridge, MA},
}

@article{lecun_deep_2015,
  title =        {Deep learning},
  volume =       521,
  number =       7553,
  journal =      {Nature},
  author =       {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year =         2015,
  pages =        {436--444},
  publisher =    {Nature Publishing Group},
}

@article{mcculloch_logical_1943,
  title =        {A logical calculus of the ideas immanent in nervous
                  activity},
  volume =       5,
  number =       4,
  journal =      {Bulletin of mathematical biophysics},
  author =       {McCulloch, Warren S. and Pitts, Walter},
  year =         1943,
  pages =        {115--133},
}

@inproceedings{vaswani_attention_2017,
  title =        {Attention is All You Need},
  booktitle =    {Advances in Neural Information Processing Systems},
  author =       {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki
                  and Uszkoreit, Jakob and Jones, Llion and Gomez,
                  Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  volume =       30,
  year =         2017,
  publisher =    {Curran Associates, Inc.},
  url =
                  {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},
}

@book{jurafsky_speech_2024,
  title =        {Speech and Language Processing: An Introduction to
                  Natural Language Processing, Computational
                  Linguistics, and Speech Recognition},
  author =       {Jurafsky, Daniel and Martin, James H.},
  edition =      {3rd draft},
  year =         2024,
  publisher =    {Online draft},
  url =          {https://web.stanford.edu/~jurafsky/slp3/},
}

@article{brown_language_2020,
  title =        {Language Models are Few-Shot Learners},
  author =       {Brown, Tom and Mann, Benjamin and Ryder, Nick and
                  Subbiah, Melanie and Kaplan, Jared and Dhariwal,
                  Prafulla and Neelakantan, Arvind and Shyam, Pranav
                  and Sastry, Girish and Askell, Amanda},
  journal =      {Advances in Neural Information Processing Systems},
  volume =       33,
  pages =        {1877--1901},
  year =         2020,
  url =
                  {https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf},
}

@article{ouyang_training_2022,
  title =        {Training language models to follow instructions with
                  human feedback},
  author =       {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and
                  Almeida, Diogo and Wainwright, Carroll and Mishkin,
                  Pamela and Zhang, Chong and Agarwal, Sandhini and
                  Slama, Katarina and Ray, Alex},
  journal =      {Advances in Neural Information Processing Systems},
  volume =       35,
  pages =        {27730--27744},
  year =         2022,
  url =
                  {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a0017cc-Paper.pdf},
}

@article{zhao_survey_2023,
  title =        {A Survey of Large Language Models},
  author =       {Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and
                  Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and
                  Min, Yingqian and Zhang, Beichen and Zhang, Junjie
                  and Dong, Zican},
  journal =      {arXiv preprint arXiv:2303.18223},
  year =         2023,
  url =          {https://arxiv.org/abs/2303.18223},
}

@article{rumelhartLearningRepresentationsBackpropagating1986,
  title =        {Learning Representations by Back-Propagating Errors},
  author =       {Rumelhart, David E. and Hinton, Geoffrey E. and
                  Williams, Ronald J.},
  date =         {1986-10},
  journaltitle = {Nature},
  volume =       {323},
  number =       {6088},
  pages =        {533--536},
  publisher =    {Nature Publishing Group},
  issn =         {1476-4687},
  doi =          {10.1038/323533a0},
  url =          {https://www.nature.com/articles/323533a0},
  urldate =      {2025-12-04},
  abstract =     {We describe a new learning procedure,
                  back-propagation, for networks of neurone-like
                  units. The procedure repeatedly adjusts the weights
                  of the connections in the network so as to minimize
                  a measure of the difference between the actual
                  output vector of the net and the desired output
                  vector. As a result of the weight adjustments,
                  internal ‘hidden’ units which are not part of the
                  input or output come to represent important features
                  of the task domain, and the regularities in the task
                  are captured by the interactions of these units. The
                  ability to create useful new features distinguishes
                  back-propagation from earlier, simpler methods such
                  as the perceptron-convergence procedure1.},
  langid =       {english},
  keywords =     {Humanities and Social
                  Sciences,multidisciplinary,Science},
  year =         {1986}
}

@online{raffelExploringLimitsTransfer2019,
  title =        {Exploring the {{Limits}} of {{Transfer Learning}}
                  with a {{Unified Text-to-Text Transformer}}},
  author =       {Raffel, Colin and Shazeer, Noam and Roberts, Adam
                  and Lee, Katherine and Narang, Sharan and Matena,
                  Michael and Zhou, Yanqi and Li, Wei and Liu, Peter
                  J.},
  date =         {2019-10-23},
  url =          {https://arxiv.org/abs/1910.10683v4},
  urldate =      {2025-12-04},
  abstract =     {Transfer learning, where a model is first
                  pre-trained on a data-rich task before being
                  fine-tuned on a downstream task, has emerged as a
                  powerful technique in natural language processing
                  (NLP). The effectiveness of transfer learning has
                  given rise to a diversity of approaches,
                  methodology, and practice. In this paper, we explore
                  the landscape of transfer learning techniques for
                  NLP by introducing a unified framework that converts
                  all text-based language problems into a text-to-text
                  format. Our systematic study compares pre-training
                  objectives, architectures, unlabeled data sets,
                  transfer approaches, and other factors on dozens of
                  language understanding tasks. By combining the
                  insights from our exploration with scale and our new
                  ``Colossal Clean Crawled Corpus'', we achieve
                  state-of-the-art results on many benchmarks covering
                  summarization, question answering, text
                  classification, and more. To facilitate future work
                  on transfer learning for NLP, we release our data
                  set, pre-trained models, and code.},
  langid =       {english},
  organization = {arXiv.org},
}

@article{turingComputableNumbersApplication1937,
  title =        {On {{Computable Numbers}}, with an {{Application}}
                  to the {{Entscheidungsproblem}}},
  author =       {Turing, A. M.},
  date =         {1937},
  journaltitle = {Proceedings of the London Mathematical Society},
  volume =       {s2-42},
  number =       {1},
  pages =        {230--265},
  issn =         {1460-244X},
  doi =          {10.1112/plms/s2-42.1.230},
  url =
                  {https://onlinelibrary.wiley.com/doi/abs/10.1112/plms/s2-42.1.230},
  urldate =      {2025-12-13},
  langid =       {english},
  year =         {1937}
}

@article{hochreiter_long_1997,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997}
}

@inproceedings{strubell_energy_2019,
  title={Energy and Policy Considerations for Deep Learning in NLP},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={3645--3650},
  year={2019}
}

@article{bengio_learning_1994,
  title={Learning long-term dependencies with gradient descent is difficult},
  author={Bengio, Yoshua and Simard, Patrice and Frasconi, Paolo},
  journal={IEEE transactions on neural networks},
  volume={5},
  number={2},
  pages={157--166},
  year={1994}
}


@article{fullerDigitalTwinEnabling2020,
  title =        {Digital {{Twin}}: {{Enabling Technologies}},
                  {{Challenges}} and {{Open Research}}},
  shorttitle =   {Digital {{Twin}}},
  author =       {Fuller, Aidan and Fan, Zhong and Day, Charles and
                  Barlow, Chris},
  date =         {2020},
  journaltitle = {IEEE Access},
  volume =       {8},
  pages =        {108952--108971},
  issn =         {2169-3536},
  doi =          {10.1109/ACCESS.2020.2998358},
  url =          {https://ieeexplore.ieee.org/document/9103025},
  urldate =      {2025-12-17},
  abstract =     {Digital Twin technology is an emerging concept that
                  has become the centre of attention for industry and,
                  in more recent years, academia. The advancements in
                  industry 4.0 concepts have facilitated its growth,
                  particularly in the manufacturing industry. The
                  Digital Twin is defined extensively but is best
                  described as the effortless integration of data
                  between a physical and virtual machine in either
                  direction. The challenges, applications, and
                  enabling technologies for Artificial Intelligence,
                  Internet of Things (IoT) and Digital Twins are
                  presented. A review of publications relating to
                  Digital Twins is performed, producing a categorical
                  review of recent papers. The review has categorised
                  them by research areas: manufacturing, healthcare
                  and smart cities, discussing a range of papers that
                  reflect these areas and the current state of
                  research. The paper provides an assessment of the
                  enabling technologies, challenges and open research
                  for Digital Twins.},
  keywords =     {applications,Computational modeling,Data
                  analysis,Data models,deep learning,Digital
                  twins,enabling technologies,industrial Internet of
                  Things (IIoT),Internet of Things,Internet of Things
                  (IoT),literature review,machine
                  learning,Manufacturing,Smart cities}
}

@article{gallegoEventBasedVisionSurvey2022,
  title =        {Event-{{Based Vision}}: {{A Survey}}},
  shorttitle =   {Event-{{Based Vision}}},
  author =       {Gallego, Guillermo and Delbrück, Tobi and Orchard,
                  Garrick and Bartolozzi, Chiara and Taba, Brian and
                  Censi, Andrea and Leutenegger, Stefan and Davison,
                  Andrew J. and Conradt, Jörg and Daniilidis, Kostas
                  and Scaramuzza, Davide},
  date =         {2022-01},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine
                  Intelligence},
  volume =       {44},
  number =       {1},
  pages =        {154--180},
  issn =         {1939-3539},
  doi =          {10.1109/TPAMI.2020.3008413},
  url =          {https://ieeexplore.ieee.org/document/9138762},
  urldate =      {2025-12-17},
  abstract =     {Event cameras are bio-inspired sensors that differ
                  from conventional frame cameras: Instead of
                  capturing images at a fixed rate, they
                  asynchronously measure per-pixel brightness changes,
                  and output a stream of events that encode the time,
                  location and sign of the brightness changes. Event
                  cameras offer attractive properties compared to
                  traditional cameras: high temporal resolution (in
                  the order of μμs), very high dynamic range (140 dB
                  versus 60 dB), low power consumption, and high pixel
                  bandwidth (on the order of kHz) resulting in reduced
                  motion blur. Hence, event cameras have a large
                  potential for robotics and computer vision in
                  challenging scenarios for traditional cameras, such
                  as low-latency, high speed, and high dynamic range.
                  However, novel methods are required to process the
                  unconventional output of these sensors in order to
                  unlock their potential. This paper provides a
                  comprehensive overview of the emerging field of
                  event-based vision, with a focus on the applications
                  and the algorithms developed to unlock the
                  outstanding properties of event cameras. We present
                  event cameras from their working principle, the
                  actual sensors that are available and the tasks that
                  they have been used for, from low-level vision
                  (feature detection and tracking, optic flow, etc.)
                  to high-level vision (reconstruction, segmentation,
                  recognition). We also discuss the techniques
                  developed to process events, including
                  learning-based techniques, as well as specialized
                  processors for these novel sensors, such as spiking
                  neural networks. Additionally, we highlight the
                  challenges that remain to be tackled and the
                  opportunities that lie ahead in the search for a
                  more efficient, bio-inspired way for machines to
                  perceive and interact with the world.},
  keywords =     {asynchronous sensor,bio-inspired
                  vision,Brightness,Cameras,Event cameras,high dynamic
                  range,low latency,low power,Retina,Robot vision
                  systems,Voltage control}
}

@article{elnaggarProtTransUnderstandingLanguage2022,
  title =        {{{ProtTrans}}: {{Toward Understanding}} the
                  {{Language}} of {{Life Through Self-Supervised
                  Learning}}},
  shorttitle =   {{{ProtTrans}}},
  author =       {Elnaggar, Ahmed and Heinzinger, Michael and Dallago,
                  Christian and Rehawi, Ghalia and Wang, Yu and Jones,
                  Llion and Gibbs, Tom and Feher, Tamas and Angerer,
                  Christoph and Steinegger, Martin and Bhowmik,
                  Debsindhu and Rost, Burkhard},
  date =         {2022-10},
  journaltitle = {IEEE Transactions on Pattern Analysis and Machine
                  Intelligence},
  volume =       {44},
  number =       {10},
  pages =        {7112--7127},
  issn =         {1939-3539},
  doi =          {10.1109/TPAMI.2021.3095381},
  url =          {https://ieeexplore.ieee.org/document/9477085},
  urldate =      {2025-12-17},
  abstract =     {Computational biology and bioinformatics provide
                  vast data gold-mines from protein sequences, ideal
                  for Language Models (LMs) taken from Natural
                  Language Processing (NLP). These LMs reach for new
                  prediction frontiers at low inference costs. Here,
                  we trained two auto-regressive models
                  (Transformer-XL, XLNet) and four auto-encoder models
                  (BERT, Albert, Electra, T5) on data from UniRef and
                  BFD containing up to 393 billion amino acids. The
                  protein LMs (pLMs) were trained on the Summit
                  supercomputer using 5616 GPUs and TPU Pod up-to 1024
                  cores. Dimensionality reduction revealed that the
                  raw pLM-embeddings from unlabeled data captured some
                  biophysical features of protein sequences. We
                  validated the advantage of using the embeddings as
                  exclusive input for several subsequent tasks: (1) a
                  per-residue (per-token) prediction of protein
                  secondary structure (3-state accuracy Q3=81\%-87\%);
                  (2) per-protein (pooling) predictions of protein
                  sub-cellular location (ten-state accuracy: Q10=81\%)
                  and membrane versus water-soluble (2-state accuracy
                  Q2=91\%). For secondary structure, the most
                  informative embeddings (ProtT5) for the first time
                  outperformed the state-of-the-art without multiple
                  sequence alignments (MSAs) or evolutionary
                  information thereby bypassing expensive database
                  searches. Taken together, the results implied that
                  pLMs learned some of the grammar of the language of
                  life. All our models are available through
                  https://github.com/agemagician/ProtTrans.},
  keywords =     {Amino acids,Computational biology,Computational
                  modeling,Databases,deep learning,high performance
                  computing,language modeling,machine
                  learning,Proteins,Task analysis,Three-dimensional
                  displays,Training}
}

@article{tjoaSurveyExplainableArtificial2021,
  title =        {A {{Survey}} on {{Explainable Artificial
                  Intelligence}} ({{XAI}}): {{Toward Medical XAI}}},
  shorttitle =   {A {{Survey}} on {{Explainable Artificial
                  Intelligence}} ({{XAI}})},
  author =       {Tjoa, Erico and Guan, Cuntai},
  date =         {2021-11},
  journaltitle = {IEEE Transactions on Neural Networks and Learning
                  Systems},
  volume =       {32},
  number =       {11},
  pages =        {4793--4813},
  issn =         {2162-2388},
  doi =          {10.1109/TNNLS.2020.3027314},
  url =          {https://ieeexplore.ieee.org/document/9233366},
  urldate =      {2025-12-17},
  abstract =     {Recently, artificial intelligence and machine
                  learning in general have demonstrated remarkable
                  performances in many tasks, from image processing to
                  natural language processing, especially with the
                  advent of deep learning (DL). Along with research
                  progress, they have encroached upon many different
                  fields and disciplines. Some of them require high
                  level of accountability and thus transparency, for
                  example, the medical sector. Explanations for
                  machine decisions and predictions are thus needed to
                  justify their reliability. This requires greater
                  interpretability, which often means we need to
                  understand the mechanism underlying the algorithms.
                  Unfortunately, the blackbox nature of the DL is
                  still unresolved, and many machine decisions are
                  still poorly understood. We provide a review on
                  interpretabilities suggested by different research
                  works and categorize them. The different categories
                  show different dimensions in interpretability
                  research, from approaches that provide “obviously”
                  interpretable information to the studies of complex
                  patterns. By applying the same categorization to
                  interpretability in medical research, it is hoped
                  that: 1) clinicians and practitioners can
                  subsequently approach these methods with caution; 2)
                  insight into interpretability will be born with more
                  considerations for medical practices; and 3)
                  initiatives to push forward data-based,
                  mathematically grounded, and technically grounded
                  medical education are encouraged.},
  keywords =     {Artificial intelligence,Explainable artificial
                  intelligence (XAI),interpretability,Machine
                  learning,machine learning (ML),Machine learning
                  algorithms,medical information system,Medical
                  information systems,survey}
}

@article{yurtseverSurveyAutonomousDriving2020,
  title =        {A {{Survey}} of {{Autonomous Driving}}: {{Common
                  Practices}} and {{Emerging Technologies}}},
  shorttitle =   {A {{Survey}} of {{Autonomous Driving}}},
  author =       {Yurtsever, Ekim and Lambert, Jacob and Carballo,
                  Alexander and Takeda, Kazuya},
  date =         {2020},
  journaltitle = {IEEE Access},
  volume =       {8},
  pages =        {58443--58469},
  issn =         {2169-3536},
  doi =          {10.1109/ACCESS.2020.2983149},
  url =          {https://ieeexplore.ieee.org/document/9046805},
  urldate =      {2025-12-17},
  abstract =     {Automated driving systems (ADSs) promise a safe,
                  comfortable and efficient driving experience.
                  However, fatalities involving vehicles equipped with
                  ADSs are on the rise. The full potential of ADSs
                  cannot be realized unless the robustness of
                  state-of-the-art is improved further. This paper
                  discusses unsolved problems and surveys the
                  technical aspect of automated driving. Studies
                  regarding present challenges, high-level system
                  architectures, emerging methodologies and core
                  functions including localization, mapping,
                  perception, planning, and human machine interfaces,
                  were thoroughly reviewed. Furthermore, many
                  state-of-the-art algorithms were implemented and
                  compared on our own platform in a real-world driving
                  setting. The paper concludes with an overview of
                  available datasets and tools for ADS development.},
  keywords =     {Accidents,automation,Automation,Autonomous
                  vehicles,control,intelligent transportation
                  systems,intelligent vehicles,Planning,Robot sensing
                  systems,robotics,Systems architecture,Task
                  analysis,Vehicle dynamics}
}

@article{shafiqueInternetThingsIoT2020,
  title =        {Internet of {{Things}} ({{IoT}}) for
                  {{Next-Generation Smart Systems}}: {{A Review}} of
                  {{Current Challenges}}, {{Future Trends}} and
                  {{Prospects}} for {{Emerging 5G-IoT Scenarios}}},
  shorttitle =   {Internet of {{Things}} ({{IoT}}) for
                  {{Next-Generation Smart Systems}}},
  author =       {Shafique, Kinza and Khawaja, Bilal A. and Sabir,
                  Farah and Qazi, Sameer and Mustaqim, Muhammad},
  date =         {2020},
  journaltitle = {IEEE Access},
  volume =       {8},
  pages =        {23022--23040},
  issn =         {2169-3536},
  doi =          {10.1109/ACCESS.2020.2970118},
  url =          {https://ieeexplore.ieee.org/document/8972389},
  urldate =      {2025-12-17},
  abstract =     {The Internet of Things (IoT)-centric concepts like
                  augmented reality, high-resolution video streaming,
                  self-driven cars, smart environment, e-health care,
                  etc. have a ubiquitous presence now. These
                  applications require higher data-rates, large
                  bandwidth, increased capacity, low latency and high
                  throughput. In light of these emerging concepts, IoT
                  has revolutionized the world by providing seamless
                  connectivity between heterogeneous networks
                  (HetNets). The eventual aim of IoT is to introduce
                  the plug and play technology providing the end-user,
                  ease of operation, remotely access control and
                  configurability. This paper presents the IoT
                  technology from a bird's eye view covering its
                  statistical/architectural trends, use cases,
                  challenges and future prospects. The paper also
                  presents a detailed and extensive overview of the
                  emerging 5G-IoT scenario. Fifth Generation (5G)
                  cellular networks provide key enabling technologies
                  for ubiquitous deployment of the IoT technology.
                  These include carrier aggregation, multiple-input
                  multiple-output (MIMO), massive-MIMO (M-MIMO),
                  coordinated multipoint processing (CoMP),
                  device-to-device (D2D) communications, centralized
                  radio access network (CRAN), software-defined
                  wireless sensor networking (SD-WSN), network
                  function virtualization (NFV) and cognitive radios
                  (CRs). This paper presents an exhaustive review for
                  these key enabling technologies and also discusses
                  the new emerging use cases of 5G-IoT driven by the
                  advances in artificial intelligence, machine and
                  deep learning, ongoing 5G initiatives, quality of
                  service (QoS) requirements in 5G and its
                  standardization issues. Finally, the paper discusses
                  challenges in the implementation of 5G-IoT due to
                  high data-rates requiring both cloud-based platforms
                  and IoT devices based edge computing.},
  keywords =     {5G,5G mobile communication,carrier
                  aggregation,CoMP,CRAN,CRs,HetNets,Internet of
                  Things,Internet of Things (IoT),M-MIMO,Market
                  research,MIMO,Next generation
                  networking,NFV,Protocols,QoS,Quality of
                  service,SD-WSN,Security}
}

@article{amaniGoogleEarthEngine2020,
  title =        {Google {{Earth Engine Cloud Computing Platform}} for
                  {{Remote Sensing Big Data Applications}}: {{A
                  Comprehensive Review}}},
  shorttitle =   {Google {{Earth Engine Cloud Computing Platform}} for
                  {{Remote Sensing Big Data Applications}}},
  author =       {Amani, Meisam and Ghorbanian, Arsalan and Ahmadi,
                  Seyed Ali and Kakooei, Mohammad and Moghimi, Armin
                  and Mirmazloumi, S. Mohammad and Moghaddam, Sayyed
                  Hamed Alizadeh and Mahdavi, Sahel and Ghahremanloo,
                  Masoud and Parsian, Saeid and Wu, Qiusheng and
                  Brisco, Brian},
  date =         {2020},
  journaltitle = {IEEE Journal of Selected Topics in Applied Earth
                  Observations and Remote Sensing},
  volume =       {13},
  pages =        {5326--5350},
  issn =         {2151-1535},
  doi =          {10.1109/JSTARS.2020.3021052},
  url =          {https://ieeexplore.ieee.org/document/9184118},
  urldate =      {2025-12-17},
  abstract =     {Remote sensing (RS) systems have been collecting
                  massive volumes of datasets for decades, managing
                  and analyzing of which are not practical using
                  common software packages and desktop computing
                  resources. In this regard, Google has developed a
                  cloud computing platform, called Google Earth Engine
                  (GEE), to effectively address the challenges of big
                  data analysis. In particular, this platform
                  facilitates processing big geo data over large areas
                  and monitoring the environment for long periods of
                  time. Although this platform was launched in 2010
                  and has proved its high potential for different
                  applications, it has not been fully investigated and
                  utilized for RS applications until recent years.
                  Therefore, this study aims to comprehensively
                  explore different aspects of the GEE platform,
                  including its datasets, functions,
                  advantages/limitations, and various applications.
                  For this purpose, 450 journal articles published in
                  150 journals between January 2010 and May 2020 were
                  studied. It was observed that Landsat and Sentinel
                  datasets were extensively utilized by GEE users.
                  Moreover, supervised machine learning algorithms,
                  such as Random Forest, were more widely applied to
                  image classification tasks. GEE has also been
                  employed in a broad range of applications, such as
                  Land Cover/land Use classification, hydrology, urban
                  planning, natural disaster, climate analyses, and
                  image processing. It was generally observed that the
                  number of GEE publications have significantly
                  increased during the past few years, and it is
                  expected that GEE will be utilized by more users
                  from different fields to resolve their big data
                  processing challenges.},
  keywords =     {Artificial satellites,Big data,Big Data,cloud
                  computing,Cloud
                  computing,Earth,Engines,Google,Google Earth Engine
                  (GEE),Remote sensing,remote sensing (RS)}
}

@article{sharmaMachineLearningApplications2021,
  title =        {Machine {{Learning Applications}} for {{Precision
                  Agriculture}}: {{A Comprehensive Review}}},
  shorttitle =   {Machine {{Learning Applications}} for {{Precision
                  Agriculture}}},
  author =       {Sharma, Abhinav and Jain, Arpit and Gupta, Prateek
                  and Chowdary, Vinay},
  date =         {2021},
  journaltitle = {IEEE Access},
  volume =       {9},
  pages =        {4843--4873},
  issn =         {2169-3536},
  doi =          {10.1109/ACCESS.2020.3048415},
  url =          {https://ieeexplore.ieee.org/document/9311735},
  urldate =      {2025-12-17},
  abstract =     {Agriculture plays a vital role in the economic
                  growth of any country. With the increase of
                  population, frequent changes in climatic conditions
                  and limited resources, it becomes a challenging task
                  to fulfil the food requirement of the present
                  population. Precision agriculture also known as
                  smart farming have emerged as an innovative tool to
                  address current challenges in agricultural
                  sustainability. The mechanism that drives this
                  cutting edge technology is machine learning (ML). It
                  gives the machine ability to learn without being
                  explicitly programmed. ML together with IoT
                  (Internet of Things) enabled farm machinery are key
                  components of the next agriculture revolution. In
                  this article, authors present a systematic review of
                  ML applications in the field of agriculture. The
                  areas that are focused are prediction of soil
                  parameters such as organic carbon and moisture
                  content, crop yield prediction, disease and weed
                  detection in crops and species detection. ML with
                  computer vision are reviewed for the classification
                  of a different set of crop images in order to
                  monitor the crop quality and yield assessment. This
                  approach can be integrated for enhanced livestock
                  production by predicting fertility patterns,
                  diagnosing eating disorders, cattle behaviour based
                  on ML models using data collected by collar sensors,
                  etc. Intelligent irrigation which includes drip
                  irrigation and intelligent harvesting techniques are
                  also reviewed that reduces human labour to a great
                  extent. This article demonstrates how
                  knowledge-based agriculture can improve the
                  sustainable productivity and quality of the
                  product.},
  keywords =     {Agricultural engineering,Agriculture,Artificial
                  intelligence,intelligent irrigation,Internet of
                  Things,IoT,Irrigation,machine
                  learning,prediction,Sensors,Soil,Wireless sensor
                  networks}
}
