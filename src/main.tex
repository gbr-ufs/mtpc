% Classe.
\documentclass[12pt]{article}
% Pacotes.
\usepackage[T1]{fontenc} % Permite fontes com mais glifos (letras).
\usepackage{amsmath, amsthm, amssymb, mathtools} % Coisas de matemática.
\usepackage{sbc-template} % "Classe" da SBC.
\makeatletter
\let\bbl@normalsf\relax % Deixando o template da SBC compatível com o Babel.
\makeatother
\usepackage[english, brazilian]{babel} % Coisas de linguagem.
\usepackage{graphicx} % Coisas gráficas.
 % Pacote para tabelas mais elegantes (sem linhas verticais).
\usepackage{booktabs}
%% Citação.
\usepackage{csquotes} % Aspas que se ajustam ao contexto automaticamente.
\usepackage[
backend=biber, % Motor de processamento mais moderno que o bibtex.
backref=true,
dashed=false, % Desativa a substituição de nomes de autores repetidos.
giveninits=true, % Abrevia os primeiros nomes.
maxcitenames=2,
style=ext-authoryear, % O estilo da SBC não funciona com o BibLaTeX.
uniquename=init
]{biblatex}
\DeclareOuterCiteDelims{parencite}{\bibopenbracket}{\bibclosebracket} % [] para parencite.
\setcounter{biburlnumpenalty}{80}
\setcounter{biburlucpenalty}{80}
\setcounter{biburllcpenalty}{80}
\addbibresource{bibliografia.bib}
% Informações.
\title{Inteligência Artificial na Universidade Federal de Sergipe: Como o Seu Uso pode Comprometer o Aprendizado em Disciplinas Introdutórias de Programação}
\author{
  Alexis Cristian Pertile de Oliveira Filho\inst{1}\\
  Bruno Danton Carneiro Silva\inst{1}\\
  Dávisson Cavalcante Costa\inst{1}\\
  Gabriel Ferreira Bernardo\inst{1}\\
  Gabriel Santos de Souza\inst{1}\\
  Wevellyn Victória da Silva Azevedo\inst{1}
}
\address{Departamento de Computação\\
  Universidade Federal de Sergipe (UFS) -- São Cristóvão, SE -- Brazil}
% Metadados do PDF.
\usepackage{hyperref}
\makeatletter
\hypersetup{
  colorlinks=true,
  allcolors=black,
  pdftitle={\@title},
  pdfauthor={\@author},
  pdfsubject={Artigo científico apresentado à Universidade Federal de Sergipe como requisito de avaliação parcial da disciplina de Métodos e Técnicas de Pesquisa para Computação e, por conseguinte, a obtenção dos seus créditos.},
  pdfcreator={LaTeX with sbc-template},
  pdfkeywords={universidade federal de sergipe,federal university of sergipe,inteligencia artificial,artificial intelligence,educação,education,ensino superior,higher education}
}
\makeatother
% Documento.
\begin{document}

\maketitle

\begin{abstract}
  \selectlanguage{english}
  Digital tools can be found in various fields, \parencite{cornelio_historia_2021}, with Artificial Intelligence as a center piece, due to its speed and multifunctionality, being able to act in a wide rage of tasks \parencite{google_global_2025}. The current investigation is classified as applied, of exploratory and descriptive nature, adopting a mixed approach (qualiquantitative). The current study serves as a survey on the use of artificial intelligence in the academic space, helping out in the decision process in the industry. As a result, data related to agent preference and dependency degree were collected.
\end{abstract}

\begin{resumo}
  \selectlanguage{brazilian}
  Ferramentas digitais podem ser encontradas em diversos campos \parencite{cornelio_historia_2021}, tendo como ferramenta de destaque a Inteligência Artificial, devido à rapidez e multifuncionalidade, podendo realizar uma ampla variedade de tarefas \parencite{google_global_2025}. A presente investigação classifica-se como aplicada, de natureza exploratória e descritiva, adotando uma abordagem mista (qualiquantitativa). O presente estudo serve como pesquisa de opinião do uso de inteligência artificial generativa no ambiente acadêmico, auxiliando no processo de tomada de decisões na indústria. Como resultado, dados em relação à preferência de agente e grau de dependência foram coletados.
\end{resumo}

\selectlanguage{brazilian}
\frenchspacing % Espaçamento normal entre frases. O LaTeX usa o espaçamento arcaico de 2 espaços em vez de 1.

\section{Introdução}

Ferramentas digitais podem ser encontradas em diversos campos \parencite{cornelio_historia_2021}, tendo como ferramenta de destaque a Inteligência Artificial, devido à rapidez e multifuncionalidade, podendo realizar uma ampla variedade de tarefas \parencite{google_global_2025}. No meio acadêmico, o uso dessas ferramentas gera incertezas. A utilização inconsequente de \textit{Large Language Models} (LLMs) traz riscos como a dependência criativa e decisória, limitando o desenvolvimento crítico dos universitários \parencite{marrOs15Maiores2023}.

Esse uso já impacta negativamente a retenção de conhecimento \parencite{leeImpactGenerativeAI2025}. Embora focado em profissionais, o resultado é relevante para a educação. Pesquisa do \textit{Massachusetts Institute of Technology} (MIT) \parencite{kosmynaYourBrainChatGPT2025} corroborou esse cenário: participantes que utilizaram Inteligência Artificial (IA) tiveram desempenho inferior comparado aos que usaram mecanismos de busca ou apenas o cérebro. Mesmo ao alternarem para tarefas sem auxílio, o grupo que iniciou com IA manteve desempenho pior.

A popularização de LLMs como o ChatGPT no meio acadêmico torna o tema relevante. É necessário compreender o impacto do uso indiscriminado no amadurecimento cognitivo, incluindo a capacidade de aprendizado, tomada de decisões e pensamento crítico. Uma revisão sistemática de 70 estudos \parencite{delikoura2025superficialoutputssuperficiallearning} revelou que a interação frequente com LLMs pode provocar um efeito de \enquote{compreensão superficial} do conteúdo e dependência da ferramenta. A pesquisa visa investigar os efeitos do uso excessivo de geradores de texto em disciplinas de programação e suas consequências, como a redução da criatividade, raciocínio lógico, memória e atenção.

A importância da pesquisa abrange o contexto educacional e o mercado de trabalho, visto que estudantes dependentes de tecnologia serão os futuros profissionais. A análise questiona como tratar a dependência de IAs e garantir a formação crítica em uma realidade automatizada. A solução reside na administração do uso consciente e equilibrado da tecnologia, não em proibição, visando resultados educacionais significativos.

O objetivo geral deste artigo é buscar uma forma de integrar a IA na educação dessas disciplinas, em conjunto com os professores, visando potenciar o ensino assistido por tecnologia sem comprometer o desenvolvimento do raciocínio crítico e a autonomia dos estudantes.

Os objetivos específicos incluem:

\begin{enumerate}
\item Identificar a frequência do uso de inteligência artificial pelos alunos.
\item Mapear os efeitos percebidos por professores na capacidade cognitiva.
\item Investigar a correlação entre a complexidade dos problemas de programação propostos e a recorrência ao uso de ferramentas generativas.
\end{enumerate}

\section{Referencial Teórico}

Como LLMs são uma nova e popular tecnologia \parencite{openai_funding_2025}, torna-se necessário medir o impacto que o seu uso pode causar. Seja desde ao consumo de eletricidade \parencite{10748289}, até, como foco deste artigo, o aprendizado \parencite{10983758}. Neste trabalho, será avaliado o impacto destas ferramentas para a aprendizagem de programação, mediante uma pesquisa com os discentes ingressantes do período 2025.1. Isso auxiliará, por exemplo, no momento de decisão dos docentes, quando forem organizar o que irão fazer a respeito do uso destas tecnologias para as novas matérias da reformulação da grade, \textit{viz.} \enquote{Programação A}, \enquote{Programação B} e \enquote{Programação C}.

\textit{Large Language Models}, exemplificados pelo ChatGPT e Gemini, constituem modelos de Inteligência Artificial Generativa (IAG) treinados em extensos conjuntos de dados textuais \parencite{raffelExploringLimitsTransfer2019}. Tais sistemas viabilizam a geração de textos, a produção de códigos e a sumarização de informações \parencite{google_global_2025}. Observa-se a difusão dessas tecnologias no meio acadêmico a partir de 2023, motivada pela acessibilidade e pela aplicabilidade prática das soluções oferecidas \parencite{jensen_generative_2025}. Verifica-se que a disponibilidade de respostas imediatas, especificamente em tarefas de programação, altera a dinâmica do aprendizado discente. Discute-se, consequentemente, a atualização curricular visando a preservação e o desenvolvimento do raciocínio lógico \parencite{gan_large_2023}.

\subsection{Inteligência Artificial}

A Inteligência Artificial precede a própria consolidação da computação moderna. Em seu trabalho seminal de 1950, Alan Turing propôs a questão: \enquote{podem as máquinas pensar?}, estabelecendo o \enquote{Jogo da Imitação} (posteriormente conhecido como \enquote{Teste de Turing}) como um critério operacional para a inteligência \parencite{turing_computing_1950}. No entanto, o termo \enquote{Inteligência Artificial} foi formalmente cunhado apenas em 1956, durante a conferência de Dartmouth, onde John McCarthy e outros pesquisadores propuseram que \textquote{cada aspecto do aprendizado ou qualquer outra característica da inteligência pode, em princípio, ser descrita com tamanha precisão que uma máquina pode ser feita para simulá-la} \parencite{mccarthyProposalDartmouthSummer1956}. Desde então, a área evoluiu de sistemas baseados em regras simbólicas para abordagens estatísticas robustas.

Pesquisa neste campo auxiliou no desenvolvimento do conceito moderno de computador \parencite{turingComputableNumbersApplication1937}. A Inteligência Artificial é importante na área de jogos, sejam eles de tabuleiro, mediante a criação de programas jogadores \parencite{silverGeneralReinforcementLearning2018}, auxliando no desenvolvimento de novas estratégias e dos próprios jogadores \parencite{anickerWhenMachinesTake2025}, ou digitais, sendo crucial no desenvolvimento de componentes como \textit{non-playable characters} (NPCs), servindo como aliados ou adversários do jogadores \parencite{macia-lilloHybridArchitectureAIBased2025}. Auxiliam também no processo de desenvolvimento de \textit{software}, mediante geração de código com programas como o GitHub Copilot \parencite{chenEvaluatingLargeLanguage2021}. Em 2023, a plataforma GitHub divulgou que cerca de 46\% de código novo subido foi gerado pelo Copilot \parencite{dohmkeGitHubCopilotBusiness2023}.

Tem-se como pesquisadores renomados nesta área Alan Turing \parencite{turing_computing_1950}, considerado o \enquote{pai da ciência da computação teórica} \parencite{cooperAlanTuringHis2013} e Richard Stallman \parencite{stallmanForwardReasoningDependencydirected1977}, fundador do movimento de \textit{Software} Livre \parencite{stallmanGNUManifesto1983}. O movimento de \textit{Software} Livre oferece diversos programas gratuitos, tendo como destaque o \textit{GNU Compiler Collection} (GCC) \parencite{gcc}, coleção de compiladores do projeto \textit{GNU's Not Unix} (GNU). Outro colaborador importante da área é John McCarthy \parencite{mccarthyProposalDartmouthSummer1956}, desenvolvedor da família de linguagens de programação Lisp e o conceito de coletor de lixo, componente crucial no desenvolvimento de linguagens de programação de maior nível \parencite{mccarthyRecursiveFunctionsSymbolic1960}.

% TODO: Desafios

Mesmo que apresente grande avanço, o campo ainda não atingiu o seu objetivo principal de Inteligência Artificial Geral (AGI) \parencite{yenduriArtificialGeneralIntelligence2025}. AGI é um tipo de inteligência artificial teórico o qual, em contrapartida à IA moderna, a \foreignquote{english}{Weak AI}, se assemelha mais à um ser humano, por ser capaz de aprender e raciocinar nos mais variados cenários. O devensolvimento de \textit{Large Language Models} conta como um grande passo nesta direção. Todavia, não significa o fim da jornada. \textcite{yenduriArtificialGeneralIntelligence2025} descrevem que, para uma inteligência artificial atingir o nível de AGI, deve ter as seguintes capacidades: Comunicação e Linguagem (Interação Física e Habilidades Motoras, Percepção sensorial, Processamento de Linguagem Natural (NLP)), Habilidades Emocionais e Sociais (Criatividade, Inteligência Social e Emocional) e Habilidades Cognitivas (Raciocínio e Resolução de Problemas, Planejamento, Aprendizado e Adaptação, Representação de Conhecimento, Consciência e autocosciência).

\subsection{Aprendizado de Máquina}

Dentro do vasto campo da IA, destaca-se o Aprendizado de Máquina (\textit{Machine Learning}) como o subcampo responsável pelos avanços mais significativos das últimas décadas. Diferentemente da programação tradicional, onde as regras são explicitamente codificadas, o Aprendizado de Máquina foca no desenvolvimento de algoritmos que melhoram seu desempenho automaticamente através da experiência. A definição formal amplamente aceita é dada por \textcite{mitchell_machine_1997}: diz-se que um programa de computador aprende a partir da experiência \(E\), em relação a uma classe de tarefas \(T\) e medida de desempenho \(P\), se seu desempenho em \(T\), medido por \(P\), melhora com a experiência \(E\). Essa mudança de paradigma permitiu a resolução de problemas complexos, como reconhecimento de padrões e previsões estatísticas, que eram intratáveis via programação convencional.

A aplicação dessas tecnologias no cenário educacional introduz novos paradigmas e desafios. A introdução de modelos generativos, uma vertente avançada do \textit{Machine Learning} (ML), exige uma reavaliação das práticas pedagógicas. A \textcite{unesco_guidance_2023} destaca que, embora a IA generativa ofereça oportunidades para personalizar o aprendizado, a implementação requer diretrizes éticas rigorosas para garantir que a tecnologia aumente as capacidades humanas em vez de substituí-las ou atrofiar o pensamento crítico. Observa-se, portanto, uma tensão entre a eficiência oferecida pelos sistemas automatizados e a necessidade de preservar a integridade cognitiva dos estudantes \parencite{marrOs15Maiores2023, gan_large_2023}.

O ML faz-se presente em diversos campos, como na indústria, durante o desenvolvimento de gêmeos digitais \parencite{fullerDigitalTwinEnabling2020}, visão computacional \parencite{gallegoEventBasedVisionSurvey2022}, biologia computacional \parencite{elnaggarProtTransUnderstandingLanguage2022}, medicina, na detecção de doenças \parencite{tjoaSurveyExplainableArtificial2021}, condução autônoma \parencite{yurtseverSurveyAutonomousDriving2020}, internet das coisas \parencite{shafiqueInternetThingsIoT2020}, classificação de imagens \parencite{amaniGoogleEarthEngine2020} e na agricultura de precisão utilizando da capacidade de classificação de imagens para detectar doenças e plantas invasoras \parencite{sharmaMachineLearningApplications2021}.

Por mais que seja uma ferramenta importante para várias áreas, o processo de Aprendizado de Máquina pode se deparar com algumas dificuldades. Pode ser possível que os dados de treinamento não sejam suficientes, ou que o modelo não tenha o contexto necessário para tarefas mais específicas \parencite{vonruedenInformedMachineLearning2023}, as decisões das máquinas tendem a não ser bem compreendidas, devido ao modelo \enquote{caixa preta} do processo de aprendizado \parencite{tjoaSurveyExplainableArtificial2021} e as empresas tendem a não ter uma estrutura sólida para o lançamento de produtos, podendo tal problema ser resolvido pela implementação de MLOps \parencite{kreuzbergerMachineLearningOperations2023}.

Apesar de toda a evolução e importância do Aprendizado de Máquina, ele não é perfeito e enfrenta barreiras significativas que atrapalham seu uso no mundo real. Com isso, o maior problema é a exigência desses modelos na quantidade excessiva de dados para aprender, recurso nem sempre disponível em cenários específicos \parencite{vonruedenInformedMachineLearning2023}. Além disso, existem falhas que mostram claramente a necessidade de modelos mais avançados e transparentes, ou seja, superar essas lacunas é essencial para que a IA atinja todo o seu potencial. O dilema da opacidade, conhecido como \enquote{caixa preta} \parencite{vonruedenInformedMachineLearning2023}, afirma que é difícil confiar em uma decisão tomada pela máquina se ela não consegue explicar sua lógica.

\subsection{Redes Neurais Artificiais}

A evolução do Aprendizado de Máquina para lidar com dados de alta complexidade e não-linearidade fundamenta-se no desenvolvimento das Redes Neurais Artificiais (RNAs). Inspiradas biologicamente no funcionamento do sistema nervoso central, as RNAs tiveram gênese teórica estabelecida por \textcite{mcculloch_logical_1943}, que propuseram o primeiro modelo matemático de um neurônio artificial. Nesse modelo, a unidade de processamento recebe múltiplos sinais de entrada, pondera-os através de pesos sinápticos e aplica uma função de ativação para determinar a saída. Embora os modelos iniciais fossem limitados em capacidade de representação, o desenvolvimento do algoritmo de retropropagação (\textit{backpropagation}) permitiu o ajuste eficiente desses pesos em redes com múltiplas camadas, viabilizando o aprendizado supervisionado complexo \parencite{rumelhartLearningRepresentationsBackpropagating1986}.

As contribuições mais importantes deste ramo encontram-se na área da saúde. Neste campo, redes neurais artificiais auxiliam na identificação de convulsões \parencite{yangMultimodalAISystem2022}, câncer \parencite{mckinneyInternationalEvaluationAI2020} e distúrbios cardiovasculares \parencite{hannunCardiologistlevelArrhythmiaDetection2019, somaniDeepLearningElectrocardiogram2021}. Também auxiliam no campo de finanças, seja por sua capacidade de análise de sentimentos \parencite{mishevEvaluationSentimentAnalysis2020} ou pelo seu potencial de analisar o próprio mercado \parencite{zhangImpactArtificialIntelligence2020, ferreiraArtificialIntelligenceApplied2021}. Pela análise de sentimentos, são também capazes de detectar notícias potencialmente falsas \parencite{mridhaComprehensiveReviewFake2021, jiangNovelStackingApproach2021, hashmiAdvancingFakeNews2024, niMVANMultiViewAttention2021} e dicursos potencialmente odiosos \parencite{mullahAdvancesMachineLearning2021, murshedDEARNNHybridDeep2022, alatawiDetectingWhiteSupremacist2021}.Através de redes adversárias generativas, é possível gerar conteúdo \parencite{fui-hoonnahGenerativeAIChatGPT2023}, como imagens \parencite{rameshZeroShotTexttoImageGeneration2021} e vídeos \parencite{peeblesScalableDiffusionModels2023}.

Nota-se na área participação de grandes empresas, como a Bytedance \parencite{linAnimateDiffLightningCrossModelDiffusion2024}, Google \parencite{silverGeneralReinforcementLearning2018, 45381}, Meta \parencite{paszkePyTorchImperativeStyle2019, touvronLLaMAOpenEfficient2023}, NVIDIA \parencite{karrasStyleBasedGeneratorArchitecture2019}, OpenAI \parencite{vaswani_attention_2017, brown_language_2020, chenEvaluatingLargeLanguage2021, rameshZeroShotTexttoImageGeneration2021} e a Tencent \parencite{kongHunyuanVideoSystematicFramework2025}. Empresas menores, como a Stability AI e Hugging Face também colaboram no ramo \parencite{rombachHighResolutionImageSynthesis2022, heikkilaRadicalNewProject2022}. A Google é o destaque entre os agentes maiores, pois seus avanços levaram a criação da arquitetura \textit{transformer} em \citetitle{vaswani_attention_2017}, a base para os \textit{large language models} modernos. Entre os menores, a Hugging Face se destaca por oferecer uma forja git feita com foco na área, servindo até como casa para os modelos das grandes empresas mencionadas \parencite{bytedanceByteDanceAnimateDiffLightningHugging2024, tencentTencentHunyuanVideoHugging2025}.

A dificuldade de explicar o funcionamento destas ferramentas aumenta conforme mais camadas são adicionadas. Tal problemática é exacerbada em redes neurais profundas (\textit{deep neural networks}), onde encontrar a origem (como um \textit{prompt}) de uma previsão pode chegar a ser até impossível, dificultando o processo de análise e a reprodutibilidade \parencite{samekExplainingDeepNeural2021}. Também dependem de altas quantidades de dados e recursos computacionais, o que, dependendo da área, nem sempre está disponível. Esse problema pode ser resolvido pelo uso de técnicas de meta-aprendizado, isto é, uso das redes neurais para melhorar os próprios algoritmos de aprendizado \parencite{hospedalesMetaLearningNeuralNetworks2022}. A resolução destas duas problemáticas resultarão em maior transparência e eficácia, permitindo a implementação de redes neurais para os maios diversos casos de uso.

As RNAs possuem limitações críticas em interpretabilidade, eficiência e consumo de recursos. O \enquote{problema da caixa preta} é o principal obstáculo: a opacidade dos pesos internos impede a auditoria de decisões em áreas sensíveis \parencite{tjoaSurveyExplainableArtificial2021}. Modelos atuais falham em cenários de \textit{Out-of-Distribution} (OOD), onde variações mínimas nos dados causam erros graves. Existe também a lacuna da dependência massiva de dados rotulados e alto custo computacional, o que restringe o treinamento de redes profundas a grandes corporações \parencite{10748289}. No ensino de programação, essas falhas são evidentes. Ferramentas baseadas em redes neurais entregam o código final, mas não detalham o processo dedutivo. Essa falta de transparência omite a lógica subjacente, impedindo que o aluno compreenda a causalidade entre o algoritmo e o resultado. A ausência de explicações estruturadas impossibilita a correção de vícios de raciocínio, transformando o aprendizado em uma reprodução mecânica de padrões estatísticos.

\subsection{Deep Learning}

O conceito de \textit{Deep Learning} (Aprendizado Profundo) emerge como uma subcategoria das RNAs, caracterizada pela utilização de múltiplas camadas ocultas de processamento entre a entrada e a saída. Segundo \textcite{goodfellow_deep_2016}, a profundidade dessas arquiteturas permite que o computador construa conceitos complexos a partir de conceitos mais simples. Em uma abordagem de \textit{Deep Learning}, as camadas iniciais podem identificar características básicas, como arestas em uma imagem, enquanto as camadas subsequentes combinam essas características para identificar formas, objetos e, finalmente, cenas completas. Essa hierarquia de representações elimina a necessidade de extração manual de características (\textit{feature engineering}), que era um gargalo nos métodos tradicionais de IA.

A eficácia do \textit{Deep Learning} reside na capacidade de generalização em grandes volumes de dados. \textcite{lecun_deep_2015} explicam que essas técnicas aprimoraram drasticamente o estado da arte em reconhecimento de fala, reconhecimento visual e processamento de linguagem natural. O treinamento dessas redes envolve a minimização de uma função de custo, ajustando iterativamente os parâmetros internos da rede para reduzir a discrepância entre a previsão do modelo e o resultado real. A arquitetura dessas redes varia conforme a aplicação, incluindo Redes Neurais Convolucionais (CNNs) para processamento de imagens e Redes Neurais Recorrentes (RNNs) para dados sequenciais \textcite{hochreiter_long_1997}, sendo estas últimas precursoras diretas da arquitetura Transformer.

No entanto, a implementação de modelos de \textit{Deep Learning} impõe custos computacionais e energéticos significativos. A infraestrutura necessária para treinar modelos profundos, especialmente aqueles com bilhões de parâmetros como os LLMs atuais, demanda \textit{data centers} de grande escala. Estudos recentes, como o de \textcite{10748289}, analisam o impacto crescente da Inteligência Artificial no consumo global de eletricidade \textcite{strubell_energy_2019}. Verifica-se que a complexidade computacional não apenas eleva os custos operacionais, mas também levanta questões sobre a sustentabilidade ambiental do avanço tecnológico contínuo nessa área.

Sistemas de gestão de ensino superior estão se adaptando à aplicação de Deep Learning, um modelo que vem se desenvolvendo de forma rápida. Segundo \cite{fangDesignAdaptiveEnglish2025}, essas ferramentas operam através de camadas de dados, modelos profundos e aplicação, analisando o comportamento do estudante para personalizar o conteúdo. O estudo utiliza algoritmos avançados, como o de Predadores Marinhos, que otimizam essa precisão. A principal lacuna, contudo, reside na complexidade de identificar e fornecer feedback individual no ensino de programação, especificamente para falhas de lógica.

O potencial do aprendizado profundo para aprimorar a inteligência e a personalização de aplicativos é destacado por \cite{guoJAVAMobileApplication2024}. O autor analisa a inserção de redes neurais em cursos de desenvolvimento móvel em Java, implementando funcionalidades como reconhecimento de imagem e fala para atender à demanda industrial. A principal lacuna identificada permanece no despreparo dos alunos para lidar com essas inovações, devido à dificuldade de introduzir conceitos complexos de IA em currículos voltados para a prática.

\subsection{Arquitetura \textit{Transformer}}

A consolidação dos Grandes Modelos de Linguagem atuais fundamenta-se na introdução da arquitetura \textit{Transformer}, proposta originalmente por \textcite{vaswani_attention_2017}. Até o surgimento dessa arquitetura, o processamento de sequências (como textos e áudios) dependia majoritariamente de Redes Neurais Recorrentes e unidades \textit{Long Short-Term Memory} (LSTM). Tais modelos processavam os dados de forma sequencial, palavra por palavra, o que impedia a paralelização eficiente do treinamento e limitava a capacidade do sistema de \enquote{lembrar} contextos distantes dentro de um parágrafo longo. O modelo \textit{Transformer} rompeu com esse paradigma ao dispensar a recorrência em favor de mecanismos de atenção pura, permitindo o processamento simultâneo de toda a sequência de dados.

Como anteriormente mencionado, o desenvolvimento desta arquitetura revolucionou o desenvolvimento de \textit{Large Language Models} \parencite{raiaanReviewLargeLanguage2024}. A partir dela, modelos como o \textit{Bidirectional Encoder Representations from Transformers} (BERT) \parencite{devlinBERTPretrainingDeep2019} da Google e o \textit{Generative Pre-trained Transformer} (GPT) da OpenAI puderam ser desenvolvidos \parencite{radford2018improving}. O mais importante destes é o GPT, pois a partir dele foi desenvolvido o GPT-3, divulgado em \textcite{brown_language_2020}, que, unido ao trabalho de \textcite{ouyang_training_2022}, trouxe o ChatGPT ao mundo, popularizando o campo da inteligência artificial \parencite{guptaChatGPTThreatGPTImpact2023}.

Tem-se como entidades importantes para esta tecnologia a Google, por ser uma das fundadoras \parencite{vaswani_attention_2017}, além de continuar a pesquisa na área \parencite{devlinBERTPretrainingDeep2019, raffelExploringLimitsTransfer2019}, o Instituto de Inteligência Artificial Allen, em conjunto à Universidade de Washington, também se destacam, pela criação do método de \textit{embeddings from language model} (ELMo) \parencite{petersDeepContextualizedWord2018}, predecessor do BERT. A OpenAI, como anteriormente mencionado, contribuiu para o ramo com o desenvolvimento do GPT, sendo a arquitetura \textit{Transformer} o componente focal de seus modelos de texto \parencite{radford2018improving}, imagem \parencite{rameshZeroShotTexttoImageGeneration2021} e vídeo \parencite{peeblesScalableDiffusionModels2023}.

Comparados a Redes Neurais Convolucionais comuns, transformers exigem maior custo computacional, o que resulta em aumentos no tempo de treinamento e uso de memória. Tal exigência escala conforme o tamanho do \textit{dataset} \parencite{sharifiEnhancingSpatialResolution2025}. Esse fato é observável em múltiplos ramos, geralmente devido à complexidade quadrática (\(\mathcal{O}_{n^{2}}\)) de memória do processo de \textit{self-attention}, mas pode ser resolvido \parencite{yangSwin3DPretrainedTransformer2025}. Além do fator computacional, também exigem maiores quantidades de dados para treinamento, que pode ser inviável dependendo da área, ou até trazer problemas relacionados à privacidade, como no caso da área classificação de imagens médicas \parencite{hussainEFFResNetViTFusionBasedConvolutional2025}.

No campo de super-resolução de imagens de satélite, \textit{transformers} apresentam menor desempenho em imagens próximas ao infravermelho \parencite{sharifiEnhancingSpatialResolution2025}. Em processamento de imagens geral, modelos de compreensão espacial 3D são ainda inovações \parencite{yangSwin3DPretrainedTransformer2025}. A possibilidade de uma arquitetura \enquote{híbrida} que une o melhor das CNNs com o melhor dos \textit{transformers} ainda está sendo explorada \parencite{hussainEFFResNetViTFusionBasedConvolutional2025}. O uso desta tecnologia em áreas como análise sentimental é também outra novidade \parencite{dingEmTNovelTransformer2025}. A arquitetura, quando executada em escalas maiores, é incompatível com dispositivos de menor desempenho, como embarcados e vestíveis, mas pode ser otimizada para o uso em tais plataformas \parencite{busiaTinyTransformerLowPower2025}.

\subsection{\textit{Large Language Models}}

Os \textit{Large Language Models} representam a aplicação da arquitetura Transformer em uma escala massiva, tanto em termos de parâmetros computacionais quanto de volume de dados de treinamento. De acordo com \textcite{zhao_survey_2023}, o termo \foreignquote{english}{Large} refere-se a modelos que contêm de dezenas a centenas de bilhões de parâmetros. Diferentemente de modelos menores, os LLMs exibem \enquote{habilidades emergentes}, ou seja, capacidades de raciocínio e resolução de problemas que não foram explicitamente programadas, mas que surgem espontaneamente à medida que a complexidade do modelo ultrapassa certos limiares computacionais.

O desenvolvimento desta tecnologia revolucionou o ramo de processamento de linguagem natural, dando um passo na direção de \enquote{máquinas pensantes} \parencite{raiaanReviewLargeLanguage2024, turing_computing_1950}, servindo como uma ferramenta auxiliar para trabalhadores do conhecimento. Isso é notável principalmente em modelos mais recentes, que \enquote{aparentam} ter a capacidade de raciocínio \parencite{huangReasoningLargeLanguage2023}. Tais tecnologias explodiram no \textit{zeitgeist} cultural moderno, com ferramentas como o ChatGPT atingindo mais de 100 milhões de usuários em menos de dois meses de lançamento \parencite{guptaChatGPTThreatGPTImpact2023}. Devido a esse raciocínio percebido, pesquisadores estão implementando LLMs em setores cruciais, como cibersegurança e saúde \parencite{ferragRevolutionizingCyberThreat2024, qiuLargeAIModels2023}.

A disseminação dos LLMs transcende o âmbito acadêmico, encontrando usuários renomados em setores que demandam alta densidade de processamento de informação. No campo do desenvolvimento de software, engenheiros de empresas como Microsoft e Meta utilizam modelos integrados para otimização de fluxo de trabalho, enquanto no setor financeiro, instituições como o JPMorgan Chase exploram LLMs para análise de risco e sumarização de relatórios complexos \parencite{ferreiraArtificialIntelligenceApplied2021}. Além disso, figuras proeminentes na democratização da tecnologia, como Andrew Ng e Andrej Karpathy, têm sido fundamentais ao demonstrar como essas ferramentas podem atuar como \enquote{copilotos} cognitivos para estudantes e profissionais de diversas áreas. No contexto educacional, o uso por discentes de instituições de elite, como o MIT e a própria Universidade Federal de Sergipe, coloca esses modelos no centro da discussão sobre a evolução das competências digitais, transformando o LLM de um simples gerador de texto em um agente ativo na resolução de problemas interdisciplinares.

Entretanto, a simples previsão de texto não garante que o modelo seja útil ou seguro para interação humana. Para mitigar a geração de conteúdo tóxico ou alucinatório, aplica-se a técnica de Aprendizado por Reforço com Feedback Humano (RLHF). Conforme detalhado por \textcite{ouyang_training_2022}, essa metodologia consiste em coletar avaliações humanas sobre as respostas geradas pelo modelo e treinar uma \enquote{função de recompensa} que guia o LLM a alinhar suas saídas com as intenções e valores do usuário. Foi a implementação bem-sucedida dessa técnica que permitiu a transição de modelos puramente probabilísticos (como o GPT-3 original) para assistentes conversacionais instruídos (como o ChatGPT e o Gemini).

Existem problemáticas que a comunidade jamais poderá solucionar. A principal, adotada em sua maioria por filósofos da linguagem e da mente, é a de que máquinas, por diferirem em estrutura do cérebro humano, são incapazes de pensar. Tal conclusão foi estabelecida por \textcite{searleMindsBrainsPrograms1980} em seu artigo \foreignquote{english}{Minds, Brains, and Programs}, e é discutida até hoje na área \parencite{buiFoundationsArtificialIntelligence2025, liVisualRoom202025, schwitzgebelAIConsciousness2026, zhangAreMLMsTrapped2025, khamassiStrongWeakAlignment2024}. Pensadores da antiguidade também já chegaram a conclusões semelhantes \parencite{descartesDiscourseMethodRightly1993}. Decorrente disto, é tido por alguns que LLMs são geradores de \textit{bullshit} \parencite{trevisanMeasuringBullshitLanguage2024, stallmanFreeSoftwareFree2015}, isto é, pela compreensão \enquote{Frankfurtiana} da palavra, são geradores de afirmações indiferentes à verdade \parencite{frankfurtBullshit2009}.

\subsection{Impactos na Educação e no Desenvolvimento do Raciocínio Lógico}

A integração de Grandes Modelos de Linguagem (LLMs) no ambiente educacional precipitou uma transformação nas dinâmicas de ensino e aprendizagem, particularmente em disciplinas que exigem raciocínio lógico estruturado, como a programação. Conforme análise de \textcite{jensen_generative_2025}, a academia oscila entre a percepção da IA como uma ferramenta de personalização do ensino e o receio de que ela promova a atrofia de competências fundamentais. Embora a eficiência na produção de respostas seja inegável, investiga-se se a facilidade de obtenção de soluções prontas compromete a retenção do conhecimento e o desenvolvimento de habilidades cognitivas profundas.

Estudos recentes baseados em neurociência fornecem evidências quantitativas sobre os efeitos dessa dependência tecnológica. Em uma investigação utilizando eletroencefalografia (EEG), \textcite{kosmynaYourBrainChatGPT2025} demonstraram que estudantes que utilizam LLMs para realizar tarefas acadêmicas exibem uma conectividade cerebral significativamente menor nas redes neurais associadas à memória e ao planejamento, em comparação com aqueles que realizam a tarefa sem auxílio ou apenas com motores de busca. O estudo introduz o conceito de \enquote{dívida cognitiva}, sugerindo que o uso contínuo dessas ferramentas sem o devido esforço mental resulta em um desempenho neural e comportamental inferior a longo prazo, mesmo quando o estudante volta a realizar tarefas sem a ferramenta.

No contexto específico do pensamento crítico, observa-se uma correlação inversa entre a confiança na IA e o engajamento cognitivo do aluno. \textcite{leeImpactGenerativeAI2025} relatam, através de uma pesquisa com trabalhadores do conhecimento \parencite{druckerEffectiveExecutive1967}, que altos níveis de confiança na precisão do modelo levam a uma redução na verificação dos resultados e no exercício do ceticismo. Esse fenômeno é particularmente crítico no ensino de programação, onde o processo de \enquote{depuração} (\textit{debugging}) e a compreensão da sintaxe são essenciais para a formação da lógica algorítmica. Ao delegar a escrita do código à IA, o estudante pode perder a oportunidade de vivenciar o erro construtivo, etapa fundamental para a consolidação do aprendizado.

\textcite{delikoura2025superficialoutputssuperficiallearning} alertam para o risco do \enquote{aprendizado superficial} decorrente de \enquote{saídas superficiais}. A facilidade com que os LLMs geram textos fluentes e códigos funcionais pode criar uma ilusão de competência, onde o estudante acredita dominar o conteúdo apenas por ser capaz de gerar o produto final, sem compreender os processos subjacentes. Esse cenário impõe desafios urgentes às instituições de ensino, que precisam reformular métodos de avaliação para focar menos no produto final e mais no processo de raciocínio e na defesa oral das soluções apresentadas.

Em suma, a literatura atual indica que, embora os LLMs possuam potencial como tutores auxiliares, seu uso irrestrito e não supervisionado tende a substituir, em vez de complementar, o esforço cognitivo necessário para o aprendizado profundo. Diante da onipresença dessas ferramentas, conclui-se que a adaptação curricular não é apenas desejável, mas imperativa para garantir que as futuras gerações de profissionais mantenham a capacidade de pensar, analisar e criar de forma autônoma.

\section{Trabalhos Relacionados}

A integração de LLMs no ensino de programação tem despertado debate crescente na literatura acadêmica recente. Diversos estudos investigam como ferramentas baseadas em Inteligência Artificial Generativa influenciam o desempenho técnico e o desenvolvimento cognitivo de estudantes de computação \parencite{martin-gomezAIHigherEducation2025, meloUsoChatGPTNo2023, xie2024integrating, woodbridgeTopicDiscoveryClassification2025}. A análise das pesquisas correlatas revela dicotomia entre o aumento imediato da produtividade na escrita de código e os riscos de uma compreensão superficial dos fundamentos algorítmicos. Esta seção revisa quatro trabalhos fundamentais que abordam o impacto dessas tecnologias na autonomia intelectual e na retenção de conhecimento por discentes em níveis introdutórios, fundamentando a necessidade de novas abordagens pedagógicas.

\textcite{martin-gomezAIHigherEducation2025} analisam, mediante uma pesquisa descritiva, a integração da IA na educação superior, tendo como objetivo o treinamento dos docentes para o uso crítico e didático da ferramenta. Foram envolvidos os cursos de Tecnologia da Educação e Educação Física (\(n = 103\)). Na etapa de pesquisa popular, 88\% dos estudantes envolvidos afirmaram que a inteligência artificial deveria ser didáticamente implementada no ensino superior. Todavia, o trabalho envolveu estudantes de fora dos cursos principais de tecnologia, \textit{viz.} Engenharia De Computação, Ciência De Computação e Sistemas de Informação. A pesquisa foi realizada em uma universidade da Espanha, portanto, é possível que suas conclusões não se apliquem num contexto nacional.

\textcite{meloUsoChatGPTNo2023} discutem como o ChatGPT pode ser usado para criar exercícios e ajudar os professores. O uso do ChatGPT no ensino de programação atua como uma ferramenta de suporte capaz de identificar erros e sugerir correções e melhorias em códigos, servindo como um assistente para os alunos que estão aprendendo a programar. Os docentes também podem aproveitar o uso da ferramenta para analisar e sugerir melhorias nos trabalhos dos discentes. Contudo, frente a essa abordagem que destaca os benefícios do uso do ChatGPT, a nossa pesquisa na UFS investiga como essa facilidade pode gerar consequências negativas, como dependência e comprometer o aprendizado da lógica fundamental em disciplinas introdutórias de programação.

O estudo \citetitle{xie2024integrating} realizou uma pesquisa empírica de abordagem quantitativa, baseada em experimentos educacionais em disciplinas introdutórias de programação. A amostra foi composta por 211 estudantes de graduação matriculados no curso de Ciência da Computação e afins.  O objetivo do trabalho foi avaliar a capacidade dos estudantes em identificar e corrigir erros em códigos gerados por IA, por meio de atividades nas quais os estudantes analisavam e depuravam esses códigos. Os resultados apontam que muitos alunos apresentaram dificuldades significativas na depuração e compreensão conceitual do código produzido pela IA. Como lacunas, o estudo aponta para a ausência de evidências acerca dos impactos do uso de IA na aprendizagem à longo prazo.

\textcite{woodbridgeTopicDiscoveryClassification2025} analisam o uso de técnicas automatizadas para identificar, com foco na análise automatizada de políticas institucionais sobre o uso responsável de inteligência artificial generativa no ensino superior e classificar políticas institucionais relacionadas ao uso responsável de inteligência artificial generativa no ensino superior. A amostra foi feita de 212 documentos com regras  coletados de 22 instituições diferentes, Os resultados indicam alta precisão na identificação dos temas e dos níveis de permissão para o uso da IA, contribuindo para maior clareza e padronização das políticas educacionais. A pesquisa foi conduzida com base em instituições de ensino dos Estados Unidos, o que pode limitar a generalização dos resultados para outros contextos educacionais.

A literatura recente demonstra que, embora a IA Generativa ofereça suporte valioso na correção de erros e na formulação de políticas institucionais, há uma tendência de dificuldade discente na depuração e compreensão conceitual profunda de códigos automatizados. Nota-se que a maioria dos estudos foca em contextos internacionais (Espanha e Estados Unidos) ou em perfis de estudantes fora das carreiras de computação \textit{stricto sensu}. Esta pesquisa diferencia-se ao preencher essa lacuna geográfica e demográfica, investigando especificamente o impacto do uso dessas ferramentas na autonomia intelectual de estudantes de computação da Universidade Federal de Sergipe. Ao focar nos riscos de dependência e na possível erosão da lógica fundamental, o presente trabalho justifica-se pela necessidade de validar se os desafios globais de retenção de conhecimento se reproduzem no cenário acadêmico nacional.

\section{Metodologia}

Esta seção descreve o desenho da pesquisa, os procedimentos metodológicos adotados, os materiais utilizados e as etapas de execução, organizadas de forma a garantir a reprodutibilidade do estudo e o alinhamento entre os objetivos propostos e os resultados esperados.

A presente investigação classifica-se como aplicada, de natureza exploratória e descritiva, adotando uma abordagem mista (qualiquantitativa). Sua natureza aplicada justifica-se pelo objetivo de resolver um problema prático identificado no ambiente académico: a necessidade de integrar ferramentas de IA no ensino de programação sem comprometer o desenvolvimento cognitivo dos discentes. Adicionalmente, o estudo é exploratório devido à recência do fenômeno dos \textit{Large Language Models} e à escassez de dados específicos sobre o seu impacto na Universidade Federal de Sergipe, bem como descritivo, pois procura mapear e descrever as características de uso e as percepções de alunos e professores. A pesquisa foi realizada no Departamento de Computação da UFS, tendo como público-alvo os discentes ingressantes do período letivo 2025.1 matriculados nas disciplinas introdutórias de Programação Funcional e Programação Imperativa.

Os objetivos específicos deste trabalho foram desdobrados em questões de pesquisa (QP) fundamentais para guiar a investigação. A primeira questão (QP1) busca identificar com que frequência e intensidade os alunos ingressantes utilizam ferramentas de IA Generativa para a resolução de atividades de programação. A segunda (QP2) investiga qual é a percepção dos discentes sobre os efeitos dessas ferramentas na capacidade cognitiva, especificamente na memória e no raciocínio lógico. Por fim, a terceira questão (QP3) examina se existe uma correlação direta entre o nível de complexidade dos problemas de programação propostos e a recorrência ao uso de ferramentas generativas pelos estudantes.

Para a operacionalização da pesquisa, foram selecionados recursos com base na sua acessibilidade e capacidade de análise de dados. Como instrumentos de coleta, foram utilizados formulários eletrônicos (Google Forms) para a aplicação de questionários estruturados aos discentes. Para o processamento estatístico das respostas quantitativas e a identificação de padrões de uso, serão empregadas ferramentas de análise baseadas na linguagem Python com bibliotecas de dados. Além disso, a fundamentação teórica e a comparação com trabalhos relacionados serão realizadas através de consultas a bases de dados bibliográficas reconhecidas. A tabela a seguir detalha essas bases.

\begin{table}[ht]
  \centering
  \begin{tabular}{c}
    \toprule
    Bases de Dados Bibliográficos \\
    \midrule
    ACM Digital Library \\
    Arxiv \\
    Google Scholar \\
    IEEE Xplore \\
    \bottomrule
  \end{tabular}
  \caption{Bases de Dados Bibliográficos}
  \label{tab:bases-bibiliograficas}
\end{table}

Os procedimentos adotados dividem-se em quatro fases estratégicas. Inicialmente, realiza-se uma Revisão Sistemática da Literatura para levantar o estado da arte sobre LLMs na educação, focando em estudos recentes que abordam a \enquote{dívida cognitiva} e o \enquote{aprendizado superficial}. A fase seguinte consiste no desenvolvimento do instrumento, com a elaboração de um questionário validado para verificar as hipóteses de dependência tecnológica e redução da prática de debugging. Posteriormente, ocorre a coleta de dados mediante a aplicação do questionário aos alunos das disciplinas alvo ao final do semestre letivo, garantindo uma amostragem representativa dos ingressantes. Por fim, a etapa de análise e triangulação envolve o processamento dos dados quantitativos para responder às questões de pesquisa e a comparação qualitativa com as percepções recolhidas, validando se o cenário local reflete as tendências globais identificadas no referencial teórico.

O cronograma de execução foi estruturado em cinco etapas com seus respectivos entregáveis. A Etapa 1 (Fundamentação) foca na definição do problema e na escrita do Referencial Teórico, resultando no Capítulo 2 do artigo. A Etapa 2 (Instrumentação) abrange a definição das perguntas do questionário e a seleção da população-alvo, entregando o link do formulário de pesquisa. Na Etapa 3 (Campo), realiza-se a coleta de respostas junto aos discentes de Programação Funcional e Programação Imperativa, gerando a base de dados bruta. A Etapa 4 (Análise) consiste no tratamento dos dados e na geração de gráficos de correlação para obter os resultados preliminares. Finalmente, a Etapa 5 (Conclusão) encerra o trabalho com a redação final, discussão dos resultados e defesa, culminando na submissão do artigo completo.

A eficácia da metodologia será avaliada através da consistência estatística dos dados coletados e da capacidade de responder às perguntas de pesquisa formuladas. A validação ocorrerá pela comparação dos resultados obtidos na UFS com estudos similares, como os realizados pelo MIT \parencite{kosmynaYourBrainChatGPT2025} e Microsoft \parencite{leeImpactGenerativeAI2025}, permitindo verificar se o fenômeno da redução do desempenho em tarefas não assistidas se repete no contexto local.

\section{Análise e Discussão dos Resultados}

Esta seção tem como objetivo apresentar, analisar e discutir os dados obtidos através da pesquisa de campo realizada com discentes dos cursos de Engenharia de Computação, Ciência da Computação e Sistemas de Informação da Universidade Federal de Sergipe . A análise visa confrontar os resultados empíricos com as Perguntas de Pesquisa (QP) estabelecidas e com a literatura levantada no referencial teórico. Os dados foram coletados mediante questionários aplicados a uma amostra de 26 estudantes de disciplinas introdutórias de programação, permitindo um mapeamento quantitativo e qualitativo sobre a frequência de uso, a percepção cognitiva e os contextos de aplicação de ferramentas de Inteligência Artificial Generativa.

\textbf{A primeira pergunta de pesquisa (QP1)} buscou investigar: \enquote{Com que frequência e intensidade os alunos ingressantes utilizam ferramentas de IA Generativa para a resolução de atividades de programação?}. Compreender a intensidade de uso é o primeiro passo para dimensionar o impacto da tecnologia no ecossistema acadêmico local. As figuras a seguir detalham a frequência, e as principais ferramentas utilizadas.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/frequency}
  \caption{Frequência de utilização de ferramentas de IA por discentes.}
  \label{fig:frequency}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/tools}
  \caption{Ferramentas de IA mais utilizadas pelos estudantes.}
  \label{fig:tools}
\end{figure}

As Figuras \ref{fig:frequency} e \ref{fig:tools} ilustram o perfil de adoção da tecnologia. A visualização por gráfico de barras horizontais foi escolhida para evidenciar a distribuição da frequência e a popularidade das ferramentas. Observa-se que o uso é predominante: somando-se as categorias \enquote{Regularmente} (11) e \enquote{Frequentemente} (8), tem-se que 73\% da amostra recorre à IA de forma habitual. Apenas 2 alunos indicaram uso \enquote{Sempre} e 5 \enquote{Raramente}. Quanto às ferramentas, nota-se uma liderança do Gemini (24 indicações), seguido pelo ChatGPT (17 indicações), com presença marginal de outras ferramentas como Copilot e DeepSeek.

Os resultados confirmam que a IA Generativa já é uma realidade consolidada nas disciplinas introdutórias da UFS. A alta frequência de uso alinha-se às observações de \textcite{marrOs15Maiores2023} sobre o crescimento do uso global e otimismo em relação à IA. Não se trata mais de uma tecnologia de nicho, mas de um recurso cotidiano para a maioria dos estudantes.
Um dado divergente da literatura tradicional, que frequentemente cita o ChatGPT como sinônimo de LLM \parencite{openai_funding_2025}, é a predominância do Gemini nesta amostra. Isso pode indicar uma tendência local de preferência por ferramentas que ofereçam integração com o ecossistema Google ou janelas de contexto maiores/atualizadas, sugerindo que o monopólio inicial da OpenAI está sendo contestado no ambiente acadêmico. A onipresença dessas ferramentas reforça a necessidade de adaptação curricular mencionada por \textcite{jensen_generative_2025}, visto que ignorar a ferramenta não é mais uma opção viável.

Em resposta à QP1, constata-se que a frequência de uso é alta e regular, caracterizando uma integração profunda da IA na rotina de estudos. A intensidade do uso, majoritariamente concentrada no Gemini e ChatGPT, indica que os alunos ingressantes já veem a IA como parte integrante do \enquote{kit de ferramentas} do programador, superando a fase de experimentação inicial.

\textbf{A segunda pergunta (QP2)} investigou: \enquote{Qual é a percepção dos discentes sobre os efeitos dessas ferramentas na capacidade cognitiva, especificamente na memória e raciocínio lógico?}. Esta análise busca contrastar a hipótese da \enquote{dívida cognitiva} com a autopercepção dos estudantes. As figuras a seguir ilustram exatamente tal questão.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/learning}
  \caption{Autopercepção sobre a qualidade do aprendizado com uso de IA.}
  \label{fig:learning}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/debugging}
  \caption{Percepção de dependência na tarefa de depuração (debugging).}
  \label{fig:debugging}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/test}
  \caption{Nível de confiança para resolver problemas sem auxílio tecnológico.}
  \label{fig:test}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/action}
  \caption{Ação tomada após a geração de código.}
  \label{fig:action}
\end{figure}

Os gráficos acima buscam correlacionar a sensação de aprendizado com a confiança técnica. A Figura \ref{fig:learning} revela uma divisão: enquanto 12 alunos sentem que o aprendizado é igual, 10 (quase 40\%) admitem que ele se torna superficial. Contudo, as Figuras \ref{fig:debugging} e \ref{fig:test} mostram uma alta autoconfiança: 17 alunos afirmam conseguir depurar sem a IA e 23 relatam confiança \enquote{Média} ou \enquote{Alta} para realizar provas sem consulta. A análise destes dados aponta para uma dissonância cognitiva potencial. A literatura, especificamente \citetitle{kosmynaYourBrainChatGPT2025}, fornece evidências neurocientíficas de que o uso de IA reduz a conectividade cerebral e gera \enquote{dívida cognitiva}. No entanto, os alunos da UFS demonstram alta confiança em suas habilidades manuais (Figuras \ref{fig:debugging} e \ref{fig:test}).

Essa confiança pode ser interpretada de duas formas: (1) os alunos estão de fato utilizando a IA de forma complementar, lendo linha por linha -- conforme evidenciado na figura \ref{fig:action} -- onde 12 alunos relatam essa prática), ou (2) estamos diante do efeito Dunning-Kruger \parencite{jornal_usp_2023}, onde a facilidade de gerar código com a IA infla a percepção de competência do aluno, mascarando lacunas de conhecimento que só apareceriam em uma avaliação prática rigorosa.

Ainda assim, o fato de 10 alunos reconhecerem explicitamente o aprendizado superficial valida a preocupação de \textcite{delikoura2025superficialoutputssuperficiallearning} sobre os riscos de saídas superficiais. Há uma consciência latente entre os discentes de que o atalho cognitivo pode ter custos a longo prazo.
Respondendo à QP2, a percepção dos discentes é ambivalente. Embora mantenham altos níveis de confiança em sua autonomia e capacidade de resolução de problemas sem IA, uma parcela significativa reconhece a superficialidade no processo de aprendizagem assistido. Isso sugere que a dívida cognitiva é um fenômeno percebido, mas talvez subestimado pelos estudantes em relação às suas reais capacidades técnicas.

\textbf{A terceira pergunta (QP3)} analisou: \enquote{Existe uma correlação direta entre o nível de complexidade dos problemas de programação propostos e a recorrência ao uso de ferramentas generativas pelos estudantes?}. A figura a seguir detalha onde os discentes mais sentem a necessidade de utilizar agentes.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{img/step}
  \caption{Etapa do desenvolvimento de código onde a necessidade de IA é maior.}
  \label{fig:step}
\end{figure}

A Figura \ref{fig:step} destaca de forma contundente o contexto de uso: 20 respondentes (77\%) indicam que a IA é necessária principalmente na \enquote{Correção de erros de sintaxe ou bugs (Depuração)}, enquanto apenas 5 a utilizam para a \enquote{Escrita da lógica inicial}. Este resultado refuta a ideia de que os alunos usam a IA apenas para gerar o código do zero para evitar o esforço lógico. A correlação identificada não é com a concepção do algoritmo, mas com a etapa de correção e manutenção. Os alunos parecem enfrentar o bloqueio não na lógica, mas na sintaxe e na identificação de erros.

Embora isso possa parecer um uso positivo (como um tutor), \textcite{leeImpactGenerativeAI2025} alertam que a redução do esforço cognitivo, mesmo na verificação, diminui o ceticismo e a atenção. Ao delegar o debugging para a IA, o aluno perde a oportunidade de aprender com o erro construtivo, essencial para a fixação de conceitos em linguagens de programação. A IA atua, portanto, como um redutor de frustração, mas possivelmente também como um redutor da resiliência intelectual necessária para a programação complexa.

\subsection{Tendências}

O objetivo desta seção é sintetizar os principais padrões identificados durante a análise dos dados e assegurar a confiabilidade das interpretações realizadas. Torna-se fundamental distinguir a identificação de tendências — que foca no reconhecimento de padrões comportamentais recorrentes — da validação dos resultados, que busca atestar a veracidade e a precisão dos achados através de métodos comparativos ou teóricos \parencite{leeImpactGenerativeAI2025}. Esta etapa é indispensável para reforçar a robustez, consistência e a credibilidade do estudo, garantindo que as conclusões sobre o uso de IA no Departamento de Computação da UFS não sejam apenas observações isoladas, mas reflexos de fenômenos acadêmicos estruturados.

Neste estudo, entende-se por \enquote{tendências} os padrões de comportamento e percepção que demonstram uma direção predominante no uso de ferramentas de Inteligência Artificial pelos discentes, impactando diretamente a dinâmica pedagógica \parencite{jensen_generative_2025}. A identificação desses padrões é relevante pois permite antecipar desafios e adaptar metodologias de ensino antes que comportamentos de risco, como a dependência cognitiva e a perda de habilidades críticas, se tornem irreversíveis \parencite{marrOs15Maiores2023}. Tais tendências foram extraídas a partir da análise estatística dos resultados obtidos na Seção 5, cruzando dados de frequência de uso, tipos de ferramentas e autopercepção de competência.

Para a consolidação dessas tendências, foram utilizados os dados quantitativos coletados via questionário (\(n=26\)). Os critérios adotados para classificar um comportamento como tendência basearam-se na recorrência (padrões observados na maioria da amostra) e na intensidade das respostas relatadas. Houve um agrupamento dos dados em categorias comportamentais para isolar fenômenos específicos de adoção tecnológica.

A primeira tendência identificada é a \textbf{migração de preferência para o ecossistema Gemini} em detrimento do ChatGPT. As evidências nos dados mostram que 24 dos 26 alunos utilizam a ferramenta da Google (Figura 2). Este dado diverge da literatura inicial, que frequentemente aponta o ChatGPT como a ferramenta hegemônica e sinônimo de LLMs no mercado \parencite{guptaChatGPTThreatGPTImpact2023, openai_funding_2025}.

A segunda tendência é o \textbf{\enquote{Hiato de Percepção de Competência}}. Observa-se que, embora cerca de 40\% dos alunos reconheçam que o aprendizado se torna superficial (Figura 3) -- corroborando o conceito de \enquote{compreensão superficial} descrito por \textcite{delikoura2025superficialoutputssuperficiallearning} -- os níveis de confiança para realizar tarefas sem auxílio permanecem elevados (Figura 5).

A terceira tendência refere-se ao \textbf{uso da IA predominantemente para depuração (\textit{debugging})}, com 77\% dos alunos utilizando a ferramenta para correção de erros em vez da escrita lógica inicial (Figura 7). Este comportamento dialoga diretamente com os achados de \textcite{xie2024integrating}, que identificam a depuração de códigos gerados por IA como um ponto crítico onde os estudantes frequentemente falham em compreender a lógica subjacente.

A análise interpretativa dessas tendências indica uma mudança na interação cognitiva dos discentes da UFS. A predominância do uso para depuração sugere que a IA está substituindo o processo de resiliência intelectual necessário para encontrar erros, alinhando-se aos alertas sobre a redução do engajamento cognitivo e do ceticismo profissional relatados por \textcite{leeImpactGenerativeAI2025}. Além disso, o hiato de confiança aponta para uma possível superestimação da competência técnica (Efeito Dunning-Kruger), onde a facilidade de uso da ferramenta mascara lacunas de aprendizado profundo e cria uma falsa sensação de domínio \parencite{delikoura2025superficialoutputssuperficiallearning}.

\subsection{Validação e Ameaças à Validade}

A validação dos resultados é necessária para assegurar que as percepções coletadas na UFS possuem eco em cenários globais e não são fruto de viés amostral. Para este estudo, a validação foi realizada por meio da \textbf{comparação com trabalhos relacionados de alto impacto}, confrontando os dados locais com as pesquisas do MIT \parencite{kosmynaYourBrainChatGPT2025} e da Microsoft \parencite{leeImpactGenerativeAI2025}.

A convergência entre o \enquote{aprendizado superficial} admitido por parcela significativa dos respondentes e a \enquote{dívida cognitiva} comprovada via eletroencefalograma por \textcite{kosmynaYourBrainChatGPT2025} valida a premissa de que o uso intensivo de IA afeta a memória de longo prazo e o planejamento lógico. Da mesma forma, a dependência observada na etapa de depuração valida as preocupações levantadas por \textcite{xie2024integrating} sobre a dificuldade dos alunos em avaliarem criticamente o código quando a IA atua como intermediária.

Apesar da consistência dos achados, o estudo apresenta certas ameaças à validade que devem ser consideradas:

\begin{itemize}
    \item \textbf{Validade Externa:} O tamanho reduzido da amostra (\(n=26\)) e o foco geográfico em uma única instituição (UFS) limitam a generalização estatística dos resultados para outros contextos nacionais, diferindo de estudos com amostras mais amplas e diversificadas como o de \textcite{martin-gomezAIHigherEducation2025}.

    \item \textbf{Validade de Conclusão:} Existe a possibilidade de viés de desejabilidade social, onde os alunos podem ter subestimado a frequência de uso ou superestimado sua confiança para não parecerem dependentes da tecnologia perante os pesquisadores, um fenômeno observado em estudos de auto-relato \parencite{leeImpactGenerativeAI2025}.

    \item \textbf{Validade de Construção:} Os questionários baseiam-se na autopercepção (dados declaratórios). A dissonância entre a sensação de aprendizado e a confiança técnica sugere que métricas baseadas apenas na opinião do aluno podem não refletir com precisão a competência real, conforme demonstrado pelas discrepâncias neurais observadas por \textcite{kosmynaYourBrainChatGPT2025}, sendo necessária, em trabalhos futuros, a aplicação de testes práticos controlados.
\end{itemize}

\section{Conclusão}

O presente estudo teve como objetivo principal analisar a integração de ferramentas de Inteligência Artificial Generativa nas disciplinas introdutórias de programação da Universidade Federal de Sergipe, buscando compreender como seu uso impacta a autonomia e o desenvolvimento do raciocínio crítico dos discentes. A investigação tornou-se imperativa diante da necessidade de equilibrar o potencial pedagógico dessas tecnologias com os riscos de dependência cognitiva e aprendizado superficial identificados na literatura recente \parencite{jensen_generative_2025}.

Os resultados obtidos revelam um cenário de adoção massiva e regular, onde 73\% dos estudantes utilizam ferramentas de IA, com predominância notável do ecossistema Gemini, divergindo das tendências globais focadas no ChatGPT \parencite{openai_funding_2025}. Identificou-se que o uso primordial dessas ferramentas (77\%) ocorre na etapa de depuração (\textit{debugging}) e correção de sintaxe, e não na concepção lógica inicial. Além disso, constatou-se uma dissonância cognitiva relevante: embora parcela significativa dos alunos reconheça a superficialidade do aprendizado assistido, os níveis de confiança na própria competência técnica permanecem elevados, sugerindo uma possível superestimação das habilidades reais mascarada pela eficiência da ferramenta.

Como contribuição científica, este trabalho valida, no contexto local e específico da Ciência da Computação, o conceito de \enquote{dívida cognitiva} e os desafios de depuração apontados por estudos internacionais, demonstrando que a facilidade de gerar código não se traduz necessariamente em compreensão dos fundamentos \parencite{kosmynaYourBrainChatGPT2025, xie2024integrating}. Em termos práticos, a pesquisa fornece subsídios para que o corpo docente da UFS reavalie os métodos avaliativos, indicando que o foco do ensino deve migrar da sintaxe — facilmente resolvida pela IA — para a defesa da lógica e a resolução de problemas complexos em ambientes controlados.

É necessário, contudo, reconhecer as limitações deste estudo. A amostra reduzida (\(n=26\)) e restrita a uma única instituição impede a generalização estatística dos resultados para o cenário nacional. Ademais, a natureza declaratória dos dados (autopercepção) pode conter vieses de desejabilidade social, onde a confiança relatada pelos alunos pode não corresponder ao desempenho prático real \parencite{leeImpactGenerativeAI2025}.

Para trabalhos futuros, sugere-se a realização de experimentos práticos controlados, onde o desempenho de codificação dos alunos seja mensurado objetivamente com e sem o auxílio de IA, superando as limitações do auto-relato. Recomenda-se também a expansão da pesquisa para outras instituições de ensino superior do Nordeste, visando mapear se a preferência pelo Gemini e o comportamento de depuração assistida são tendências regionais ou isoladas. Em suma, a integração da IA no ensino é irreversível, e o desafio reside não na proibição, mas na formação de profissionais capazes de auditar, e não apenas consumir, o código gerado por máquinas.

\printbibliography

\end{document}
